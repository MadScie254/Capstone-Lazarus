{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7d68cda",
   "metadata": {},
   "source": [
    "# üå± CAPSTONE-LAZARUS: Plant Disease Detection - Data Exploration & Model Training\n",
    "\n",
    "## üìä Project Overview\n",
    "This notebook provides a comprehensive exploration and training pipeline for **AI-powered plant disease detection**. We're building a robust system to help farmers and agronomists quickly diagnose plant health issues from leaf images.\n",
    "\n",
    "### Key Features:\n",
    "- üîç **Multi-crop disease detection** (Corn, Potato, Tomato)\n",
    "- üìà **Class imbalance handling** with sophisticated techniques\n",
    "- üéØ **High recall for critical diseases** (minimize false negatives)\n",
    "- üì± **Mobile-ready deployment** with model compression\n",
    "- üß† **Explainable AI** with saliency maps and confidence scoring\n",
    "- üì° **Uncertainty estimation** for trustworthy predictions\n",
    "\n",
    "### Agricultural Impact:\n",
    "- Early disease detection ‚Üí **reduced crop losses**\n",
    "- Precise diagnosis ‚Üí **optimized pesticide use**\n",
    "- AI-assisted decisions ‚Üí **empowered smallholder farmers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770a420d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìö Import Essential Libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, applications, optimizers, callbacks\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Visualization & Analysis\n",
    "import shap\n",
    "import lime\n",
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "print(f\"üî• TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"üéÆ GPU Available: {tf.config.list_physical_devices('GPU')}\")\n",
    "print(f\"üß† Memory Growth Enabled\")\n",
    "\n",
    "# Configure GPU memory growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU configuration error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1b1eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üé® Configure Visualization Settings\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Custom color palette for diseases\n",
    "DISEASE_COLORS = {\n",
    "    'healthy': '#2ECC71',       # Green\n",
    "    'bacterial': '#E74C3C',     # Red\n",
    "    'fungal': '#8E44AD',        # Purple\n",
    "    'viral': '#F39C12',         # Orange\n",
    "    'pest': '#E67E22',          # Orange-red\n",
    "    'nutrient': '#3498DB',      # Blue\n",
    "    'other': '#95A5A6'          # Gray\n",
    "}\n",
    "\n",
    "# Plot configuration\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035ceda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÅ Dataset Configuration & Path Setup\n",
    "PROJECT_ROOT = Path(\"C:/Users/MadScie254/Documents/GitHub/Portifolio/Capstone-Lazarus\")\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
    "EXPERIMENTS_DIR = PROJECT_ROOT / \"experiments\"\n",
    "\n",
    "# Ensure directories exist\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "EXPERIMENTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"üìÇ Data Directory: {DATA_DIR}\")\n",
    "print(f\"ü§ñ Models Directory: {MODELS_DIR}\")\n",
    "print(f\"üî¨ Experiments Directory: {EXPERIMENTS_DIR}\")\n",
    "print(f\"‚úÖ Directory structure validated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0b95d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç Comprehensive Dataset Analysis\n",
    "\n",
    "def analyze_dataset_structure(data_dir):\n",
    "    \"\"\"Comprehensive dataset structure analysis\"\"\"\n",
    "    \n",
    "    # Get all class directories\n",
    "    class_dirs = [d for d in data_dir.iterdir() if d.is_dir()]\n",
    "    class_info = []\n",
    "    \n",
    "    total_images = 0\n",
    "    \n",
    "    for class_dir in class_dirs:\n",
    "        # Count images in each class\n",
    "        image_files = list(class_dir.glob('*.jpg')) + list(class_dir.glob('*.jpeg')) + \\\n",
    "                     list(class_dir.glob('*.png')) + list(class_dir.glob('*.JPG'))\n",
    "        \n",
    "        num_images = len(image_files)\n",
    "        total_images += num_images\n",
    "        \n",
    "        # Parse class information\n",
    "        class_name = class_dir.name\n",
    "        if '___' in class_name:\n",
    "            crop, condition = class_name.split('___', 1)\n",
    "            crop = crop.replace('(', '').replace(')', '').replace('_', ' ').title()\n",
    "        else:\n",
    "            crop = class_name\n",
    "            condition = 'Unknown'\n",
    "        \n",
    "        # Sample image for size analysis\n",
    "        if image_files:\n",
    "            sample_img = Image.open(image_files[0])\n",
    "            img_width, img_height = sample_img.size\n",
    "        else:\n",
    "            img_width, img_height = 0, 0\n",
    "        \n",
    "        class_info.append({\n",
    "            'class_name': class_name,\n",
    "            'crop': crop,\n",
    "            'condition': condition,\n",
    "            'num_images': num_images,\n",
    "            'sample_width': img_width,\n",
    "            'sample_height': img_height,\n",
    "            'directory': class_dir\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(class_info)\n",
    "    \n",
    "    print(f\"üåæ Dataset Overview:\")\n",
    "    print(f\"   üìä Total Classes: {len(class_dirs)}\")\n",
    "    print(f\"   üñºÔ∏è  Total Images: {total_images:,}\")\n",
    "    print(f\"   üå± Crops: {df['crop'].nunique()} ({', '.join(df['crop'].unique())})\")\n",
    "    print(f\"   ü¶† Conditions: {df['condition'].nunique()}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Analyze the dataset\n",
    "dataset_df = analyze_dataset_structure(DATA_DIR)\n",
    "dataset_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6c4ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Class Distribution Visualization\n",
    "\n",
    "def create_class_distribution_plots(df):\n",
    "    \"\"\"Create comprehensive class distribution visualizations\"\"\"\n",
    "    \n",
    "    # 1. Overall class distribution\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=('Class Distribution', 'Crop Distribution', \n",
    "                       'Condition Distribution', 'Class Imbalance Analysis'),\n",
    "        specs=[[{\"type\": \"bar\"}, {\"type\": \"pie\"}],\n",
    "               [{\"type\": \"bar\"}, {\"type\": \"scatter\"}]]\n",
    "    )\n",
    "    \n",
    "    # Class distribution bar plot\n",
    "    sorted_df = df.sort_values('num_images', ascending=False)\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=sorted_df['class_name'], y=sorted_df['num_images'],\n",
    "               name='Images per Class', marker_color='lightblue'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Crop distribution pie chart\n",
    "    crop_counts = df.groupby('crop')['num_images'].sum().reset_index()\n",
    "    fig.add_trace(\n",
    "        go.Pie(labels=crop_counts['crop'], values=crop_counts['num_images'],\n",
    "               name='Crop Distribution'),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # Condition distribution\n",
    "    condition_counts = df.groupby('condition')['num_images'].sum().reset_index()\n",
    "    condition_counts = condition_counts.sort_values('num_images', ascending=False)\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=condition_counts['condition'], y=condition_counts['num_images'],\n",
    "               name='Condition Distribution', marker_color='lightgreen'),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # Class imbalance scatter\n",
    "    df_sorted = df.sort_values('num_images', ascending=False).reset_index()\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df_sorted.index, y=df_sorted['num_images'],\n",
    "                  mode='markers+lines', name='Class Sizes',\n",
    "                  marker=dict(size=8, color='red')),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Classes\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Number of Images\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Conditions\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Number of Images\", row=2, col=1)\n",
    "    fig.update_xaxes(title_text=\"Class Rank\", row=2, col=2)\n",
    "    fig.update_yaxes(title_text=\"Number of Images\", row=2, col=2)\n",
    "    \n",
    "    fig.update_layout(height=800, title_text=\"üå± Plant Disease Dataset Analysis\", showlegend=False)\n",
    "    fig.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create distribution plots\n",
    "distribution_fig = create_class_distribution_plots(dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102109e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìà Class Imbalance Analysis & Statistics\n",
    "\n",
    "def analyze_class_imbalance(df):\n",
    "    \"\"\"Detailed class imbalance analysis\"\"\"\n",
    "    \n",
    "    # Calculate imbalance metrics\n",
    "    total_images = df['num_images'].sum()\n",
    "    min_class_size = df['num_images'].min()\n",
    "    max_class_size = df['num_images'].max()\n",
    "    mean_class_size = df['num_images'].mean()\n",
    "    median_class_size = df['num_images'].median()\n",
    "    \n",
    "    # Imbalance ratio\n",
    "    imbalance_ratio = max_class_size / min_class_size\n",
    "    \n",
    "    # Coefficient of variation\n",
    "    cv = df['num_images'].std() / df['num_images'].mean()\n",
    "    \n",
    "    # Class distribution statistics\n",
    "    print(\"üîç Class Imbalance Analysis:\")\n",
    "    print(f\"   üìä Total Images: {total_images:,}\")\n",
    "    print(f\"   üìâ Smallest Class: {min_class_size:,} images\")\n",
    "    print(f\"   üìà Largest Class: {max_class_size:,} images\")\n",
    "    print(f\"   ‚öñÔ∏è  Imbalance Ratio: {imbalance_ratio:.1f}:1\")\n",
    "    print(f\"   üìä Mean Class Size: {mean_class_size:.0f}\")\n",
    "    print(f\"   üìä Median Class Size: {median_class_size:.0f}\")\n",
    "    print(f\"   üìä Coefficient of Variation: {cv:.2f}\")\n",
    "    \n",
    "    # Risk assessment\n",
    "    if imbalance_ratio > 100:\n",
    "        risk_level = \"üî¥ CRITICAL\"\n",
    "    elif imbalance_ratio > 10:\n",
    "        risk_level = \"üü° HIGH\"\n",
    "    elif imbalance_ratio > 5:\n",
    "        risk_level = \"üü† MODERATE\"\n",
    "    else:\n",
    "        risk_level = \"üü¢ LOW\"\n",
    "    \n",
    "    print(f\"   ‚ö†Ô∏è  Imbalance Risk: {risk_level}\")\n",
    "    \n",
    "    # Classes needing attention\n",
    "    underrepresented = df[df['num_images'] < mean_class_size * 0.5]\n",
    "    if len(underrepresented) > 0:\n",
    "        print(f\"\\nüö® Underrepresented Classes (< {mean_class_size * 0.5:.0f} images):\")\n",
    "        for _, row in underrepresented.iterrows():\n",
    "            print(f\"   - {row['class_name']}: {row['num_images']} images\")\n",
    "    \n",
    "    return {\n",
    "        'total_images': total_images,\n",
    "        'imbalance_ratio': imbalance_ratio,\n",
    "        'cv': cv,\n",
    "        'underrepresented_classes': len(underrepresented)\n",
    "    }\n",
    "\n",
    "imbalance_stats = analyze_class_imbalance(dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8c26cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üñºÔ∏è Sample Images Visualization & Quality Analysis\n",
    "\n",
    "def visualize_sample_images(df, samples_per_class=3, figsize=(20, 12)):\n",
    "    \"\"\"Visualize sample images from each class with quality analysis\"\"\"\n",
    "    \n",
    "    # Select diverse classes for visualization\n",
    "    crops = df['crop'].unique()\n",
    "    selected_classes = []\n",
    "    \n",
    "    for crop in crops:\n",
    "        crop_classes = df[df['crop'] == crop]\n",
    "        # Get healthy and diseased samples\n",
    "        healthy = crop_classes[crop_classes['condition'].str.contains('healthy', case=False)]\n",
    "        diseased = crop_classes[~crop_classes['condition'].str.contains('healthy', case=False)]\n",
    "        \n",
    "        if len(healthy) > 0:\n",
    "            selected_classes.append(healthy.iloc[0])\n",
    "        if len(diseased) > 0:\n",
    "            selected_classes.extend(diseased.head(2).to_dict('records'))\n",
    "    \n",
    "    # Create subplot grid\n",
    "    n_classes = len(selected_classes)\n",
    "    cols = 4\n",
    "    rows = (n_classes + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=figsize)\n",
    "    axes = axes.flatten() if rows > 1 else [axes]\n",
    "    \n",
    "    for idx, class_info in enumerate(selected_classes):\n",
    "        if idx >= len(axes):\n",
    "            break\n",
    "            \n",
    "        # Get sample images from this class\n",
    "        image_files = list(class_info['directory'].glob('*.jpg')) + \\\n",
    "                     list(class_info['directory'].glob('*.JPG')) + \\\n",
    "                     list(class_info['directory'].glob('*.png'))\n",
    "        \n",
    "        if image_files:\n",
    "            # Load and display a random sample\n",
    "            sample_img_path = random.choice(image_files)\n",
    "            img = cv2.imread(str(sample_img_path))\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Basic image quality metrics\n",
    "            brightness = np.mean(img_rgb)\n",
    "            contrast = np.std(img_rgb)\n",
    "            \n",
    "            axes[idx].imshow(img_rgb)\n",
    "            axes[idx].set_title(f\"{class_info['crop']}\\n{class_info['condition']}\\n\"\n",
    "                              f\"Count: {class_info['num_images']}\\n\"\n",
    "                              f\"Brightness: {brightness:.1f}, Contrast: {contrast:.1f}\", \n",
    "                              fontsize=10)\n",
    "            axes[idx].axis('off')\n",
    "        else:\n",
    "            axes[idx].text(0.5, 0.5, 'No Images', ha='center', va='center')\n",
    "            axes[idx].set_title(f\"{class_info['class_name']}\")\n",
    "            axes[idx].axis('off')\n",
    "    \n",
    "    # Hide extra subplots\n",
    "    for idx in range(len(selected_classes), len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('üå± Sample Images from Plant Disease Dataset', fontsize=16, y=1.02)\n",
    "    plt.show()\n",
    "    \n",
    "    return selected_classes\n",
    "\n",
    "# Visualize sample images\n",
    "sample_classes = visualize_sample_images(dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5688121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¨ Advanced Image Quality Analysis\n",
    "\n",
    "def analyze_image_quality(df, sample_size=100):\n",
    "    \"\"\"Comprehensive image quality analysis across classes\"\"\"\n",
    "    \n",
    "    quality_metrics = []\n",
    "    \n",
    "    for _, class_info in df.iterrows():\n",
    "        class_dir = class_info['directory']\n",
    "        image_files = list(class_dir.glob('*.jpg')) + \\\n",
    "                     list(class_dir.glob('*.JPG')) + \\\n",
    "                     list(class_dir.glob('*.png'))\n",
    "        \n",
    "        if not image_files:\n",
    "            continue\n",
    "        \n",
    "        # Sample images for analysis\n",
    "        sample_files = random.sample(image_files, min(sample_size, len(image_files)))\n",
    "        \n",
    "        class_metrics = {\n",
    "            'class_name': class_info['class_name'],\n",
    "            'crop': class_info['crop'],\n",
    "            'condition': class_info['condition'],\n",
    "            'brightness_mean': [],\n",
    "            'contrast_mean': [],\n",
    "            'sharpness_mean': [],\n",
    "            'size_variance': []\n",
    "        }\n",
    "        \n",
    "        for img_file in sample_files:\n",
    "            try:\n",
    "                # Load image\n",
    "                img = cv2.imread(str(img_file))\n",
    "                if img is None:\n",
    "                    continue\n",
    "                    \n",
    "                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                # Quality metrics\n",
    "                brightness = np.mean(img_rgb)\n",
    "                contrast = np.std(img_rgb)\n",
    "                sharpness = cv2.Laplacian(img_gray, cv2.CV_64F).var()\n",
    "                \n",
    "                class_metrics['brightness_mean'].append(brightness)\n",
    "                class_metrics['contrast_mean'].append(contrast)\n",
    "                class_metrics['sharpness_mean'].append(sharpness)\n",
    "                class_metrics['size_variance'].append(img.shape[0] * img.shape[1])\n",
    "                \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        # Calculate aggregated metrics\n",
    "        if class_metrics['brightness_mean']:\n",
    "            quality_metrics.append({\n",
    "                'class_name': class_info['class_name'],\n",
    "                'crop': class_info['crop'],\n",
    "                'condition': class_info['condition'],\n",
    "                'num_images': class_info['num_images'],\n",
    "                'avg_brightness': np.mean(class_metrics['brightness_mean']),\n",
    "                'avg_contrast': np.mean(class_metrics['contrast_mean']),\n",
    "                'avg_sharpness': np.mean(class_metrics['sharpness_mean']),\n",
    "                'brightness_std': np.std(class_metrics['brightness_mean']),\n",
    "                'contrast_std': np.std(class_metrics['contrast_mean']),\n",
    "                'sharpness_std': np.std(class_metrics['sharpness_mean']),\n",
    "            })\n",
    "    \n",
    "    quality_df = pd.DataFrame(quality_metrics)\n",
    "    \n",
    "    # Visualize quality metrics\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Brightness distribution\n",
    "    quality_df.groupby('crop')['avg_brightness'].mean().plot(kind='bar', ax=axes[0,0], color='gold')\n",
    "    axes[0,0].set_title('üåü Average Brightness by Crop')\n",
    "    axes[0,0].set_ylabel('Brightness')\n",
    "    axes[0,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Contrast distribution\n",
    "    quality_df.groupby('crop')['avg_contrast'].mean().plot(kind='bar', ax=axes[0,1], color='purple')\n",
    "    axes[0,1].set_title('üìä Average Contrast by Crop')\n",
    "    axes[0,1].set_ylabel('Contrast')\n",
    "    axes[0,1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Sharpness distribution\n",
    "    quality_df.groupby('crop')['avg_sharpness'].mean().plot(kind='bar', ax=axes[1,0], color='green')\n",
    "    axes[1,0].set_title('üîç Average Sharpness by Crop')\n",
    "    axes[1,0].set_ylabel('Sharpness')\n",
    "    axes[1,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Quality consistency (coefficient of variation)\n",
    "    quality_df['brightness_cv'] = quality_df['brightness_std'] / quality_df['avg_brightness']\n",
    "    quality_df.groupby('crop')['brightness_cv'].mean().plot(kind='bar', ax=axes[1,1], color='red')\n",
    "    axes[1,1].set_title('üìè Brightness Consistency by Crop')\n",
    "    axes[1,1].set_ylabel('Coefficient of Variation')\n",
    "    axes[1,1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return quality_df\n",
    "\n",
    "print(\"üî¨ Analyzing image quality across all classes...\")\n",
    "quality_df = analyze_image_quality(dataset_df, sample_size=50)\n",
    "print(f\"‚úÖ Quality analysis completed for {len(quality_df)} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fba443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ Strategic Class Grouping & Disease Severity Analysis\n",
    "\n",
    "def create_disease_taxonomy(df):\n",
    "    \"\"\"Create a hierarchical disease taxonomy for strategic analysis\"\"\"\n",
    "    \n",
    "    taxonomy = {\n",
    "        'healthy': [],\n",
    "        'fungal_diseases': [],\n",
    "        'bacterial_diseases': [],\n",
    "        'viral_diseases': [],\n",
    "        'pest_damage': [],\n",
    "        'nutrient_deficiency': [],\n",
    "        'other_conditions': []\n",
    "    }\n",
    "    \n",
    "    # Classification rules based on condition names\n",
    "    for _, row in df.iterrows():\n",
    "        condition = row['condition'].lower()\n",
    "        class_name = row['class_name']\n",
    "        \n",
    "        if 'healthy' in condition:\n",
    "            taxonomy['healthy'].append(class_name)\n",
    "        elif any(term in condition for term in ['blight', 'rust', 'spot', 'mold', 'leaf_spot']):\n",
    "            taxonomy['fungal_diseases'].append(class_name)\n",
    "        elif 'bacterial' in condition:\n",
    "            taxonomy['bacterial_diseases'].append(class_name)\n",
    "        elif any(term in condition for term in ['virus', 'mosaic', 'curl']):\n",
    "            taxonomy['viral_diseases'].append(class_name)\n",
    "        elif any(term in condition for term in ['mite', 'spider']):\n",
    "            taxonomy['pest_damage'].append(class_name)\n",
    "        else:\n",
    "            taxonomy['other_conditions'].append(class_name)\n",
    "    \n",
    "    # Calculate group statistics\n",
    "    group_stats = []\n",
    "    for group, classes in taxonomy.items():\n",
    "        if classes:\n",
    "            group_data = df[df['class_name'].isin(classes)]\n",
    "            group_stats.append({\n",
    "                'disease_group': group,\n",
    "                'num_classes': len(classes),\n",
    "                'total_images': group_data['num_images'].sum(),\n",
    "                'avg_images_per_class': group_data['num_images'].mean(),\n",
    "                'min_images': group_data['num_images'].min(),\n",
    "                'max_images': group_data['num_images'].max(),\n",
    "                'classes': classes\n",
    "            })\n",
    "    \n",
    "    group_df = pd.DataFrame(group_stats)\n",
    "    \n",
    "    # Visualize disease taxonomy\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Disease group distribution\n",
    "    group_df.plot(x='disease_group', y='total_images', kind='bar', ax=ax1, color='skyblue')\n",
    "    ax1.set_title('üìä Images by Disease Group')\n",
    "    ax1.set_ylabel('Total Images')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Classes per group\n",
    "    group_df.plot(x='disease_group', y='num_classes', kind='bar', ax=ax2, color='lightcoral')\n",
    "    ax2.set_title('üè∑Ô∏è Classes by Disease Group')\n",
    "    ax2.set_ylabel('Number of Classes')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"üéØ Disease Taxonomy Analysis:\")\n",
    "    for _, row in group_df.iterrows():\n",
    "        print(f\"\\nüìã {row['disease_group'].replace('_', ' ').title()}:\")\n",
    "        print(f\"   Classes: {row['num_classes']}\")\n",
    "        print(f\"   Total Images: {row['total_images']:,}\")\n",
    "        print(f\"   Avg per Class: {row['avg_images_per_class']:.0f}\")\n",
    "        print(f\"   Range: {row['min_images']}-{row['max_images']} images\")\n",
    "    \n",
    "    return taxonomy, group_df\n",
    "\n",
    "# Create disease taxonomy\n",
    "disease_taxonomy, disease_groups_df = create_disease_taxonomy(dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e76f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ Advanced Data Loading & Preprocessing Pipeline\n",
    "\n",
    "class PlantDiseaseDataProcessor:\n",
    "    \"\"\"Advanced data processor for plant disease detection\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir, img_size=(224, 224), batch_size=32):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.img_size = img_size\n",
    "        self.batch_size = batch_size\n",
    "        self.class_names = None\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        \n",
    "    def create_class_mapping(self):\n",
    "        \"\"\"Create comprehensive class mapping with metadata\"\"\"\n",
    "        class_dirs = [d for d in self.data_dir.iterdir() if d.is_dir()]\n",
    "        self.class_names = sorted([d.name for d in class_dirs])\n",
    "        \n",
    "        # Enhanced class mapping with crop and condition info\n",
    "        class_mapping = {}\n",
    "        for i, class_name in enumerate(self.class_names):\n",
    "            if '___' in class_name:\n",
    "                crop, condition = class_name.split('___', 1)\n",
    "                crop = crop.replace('(', '').replace(')', '').replace('_', ' ')\n",
    "            else:\n",
    "                crop = 'Unknown'\n",
    "                condition = class_name\n",
    "            \n",
    "            class_mapping[i] = {\n",
    "                'class_name': class_name,\n",
    "                'crop': crop,\n",
    "                'condition': condition,\n",
    "                'is_healthy': 'healthy' in condition.lower(),\n",
    "                'severity': self._estimate_severity(condition)\n",
    "            }\n",
    "        \n",
    "        return class_mapping\n",
    "    \n",
    "    def _estimate_severity(self, condition):\n",
    "        \"\"\"Estimate disease severity from condition name\"\"\"\n",
    "        condition_lower = condition.lower()\n",
    "        if 'healthy' in condition_lower:\n",
    "            return 0\n",
    "        elif any(term in condition_lower for term in ['early', 'minor']):\n",
    "            return 1\n",
    "        elif any(term in condition_lower for term in ['late', 'severe', 'blight']):\n",
    "            return 3\n",
    "        else:\n",
    "            return 2  # moderate\n",
    "    \n",
    "    def load_and_prepare_data(self, validation_split=0.2, test_split=0.1, stratify=True):\n",
    "        \"\"\"Load and prepare data with advanced preprocessing\"\"\"\n",
    "        \n",
    "        # Load image paths and labels\n",
    "        image_paths = []\n",
    "        labels = []\n",
    "        \n",
    "        for class_dir in self.data_dir.iterdir():\n",
    "            if not class_dir.is_dir():\n",
    "                continue\n",
    "                \n",
    "            class_name = class_dir.name\n",
    "            image_files = list(class_dir.glob('*.jpg')) + \\\n",
    "                         list(class_dir.glob('*.JPG')) + \\\n",
    "                         list(class_dir.glob('*.png'))\n",
    "            \n",
    "            for img_path in image_files:\n",
    "                image_paths.append(str(img_path))\n",
    "                labels.append(class_name)\n",
    "        \n",
    "        # Encode labels\n",
    "        labels_encoded = self.label_encoder.fit_transform(labels)\n",
    "        self.class_names = list(self.label_encoder.classes_)\n",
    "        \n",
    "        # Stratified splitting\n",
    "        if stratify:\n",
    "            X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "                image_paths, labels_encoded, \n",
    "                test_size=validation_split + test_split,\n",
    "                stratify=labels_encoded, \n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            X_val, X_test, y_val, y_test = train_test_split(\n",
    "                X_temp, y_temp,\n",
    "                test_size=test_split / (validation_split + test_split),\n",
    "                stratify=y_temp,\n",
    "                random_state=42\n",
    "            )\n",
    "        else:\n",
    "            # Simple random splitting\n",
    "            X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "                image_paths, labels_encoded, \n",
    "                test_size=validation_split + test_split,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            X_val, X_test, y_val, y_test = train_test_split(\n",
    "                X_temp, y_temp,\n",
    "                test_size=test_split / (validation_split + test_split),\n",
    "                random_state=42\n",
    "            )\n",
    "        \n",
    "        print(f\"üìä Data Split Summary:\")\n",
    "        print(f\"   üèãÔ∏è Training: {len(X_train):,} images\")\n",
    "        print(f\"   üîç Validation: {len(X_val):,} images\") \n",
    "        print(f\"   üéØ Test: {len(X_test):,} images\")\n",
    "        print(f\"   üè∑Ô∏è Classes: {len(self.class_names)}\")\n",
    "        \n",
    "        return {\n",
    "            'train': (X_train, y_train),\n",
    "            'val': (X_val, y_val), \n",
    "            'test': (X_test, y_test),\n",
    "            'class_mapping': self.create_class_mapping()\n",
    "        }\n",
    "    \n",
    "    def create_tf_dataset(self, image_paths, labels, training=False):\n",
    "        \"\"\"Create TensorFlow dataset with advanced augmentation\"\"\"\n",
    "        \n",
    "        def load_and_preprocess_image(path, label):\n",
    "            \"\"\"Load and preprocess individual image\"\"\"\n",
    "            image = tf.io.read_file(path)\n",
    "            image = tf.image.decode_jpeg(image, channels=3)\n",
    "            image = tf.image.resize(image, self.img_size)\n",
    "            image = tf.cast(image, tf.float32) / 255.0\n",
    "            \n",
    "            if training:\n",
    "                # Advanced augmentation for training\n",
    "                image = tf.image.random_flip_left_right(image)\n",
    "                image = tf.image.random_flip_up_down(image)\n",
    "                image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "                image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
    "                image = tf.image.random_saturation(image, lower=0.9, upper=1.1)\n",
    "                image = tf.image.random_hue(image, max_delta=0.05)\n",
    "                \n",
    "                # Random rotation\n",
    "                image = tf.image.rot90(image, tf.random.uniform(shape=[], maxval=4, dtype=tf.int32))\n",
    "                \n",
    "                # Random zoom and crop\n",
    "                image = tf.image.random_crop(\n",
    "                    tf.image.resize(image, [int(self.img_size[0] * 1.1), int(self.img_size[1] * 1.1)]),\n",
    "                    size=[self.img_size[0], self.img_size[1], 3]\n",
    "                )\n",
    "            \n",
    "            return image, label\n",
    "        \n",
    "        # Create dataset\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "        dataset = dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        \n",
    "        if training:\n",
    "            dataset = dataset.shuffle(buffer_size=1000)\n",
    "            dataset = dataset.repeat()\n",
    "        \n",
    "        dataset = dataset.batch(self.batch_size)\n",
    "        dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "        \n",
    "        return dataset\n",
    "\n",
    "# Initialize data processor\n",
    "print(\"üîÑ Initializing Plant Disease Data Processor...\")\n",
    "data_processor = PlantDiseaseDataProcessor(DATA_DIR, img_size=(224, 224), batch_size=32)\n",
    "\n",
    "# Load and prepare data\n",
    "print(\"üì• Loading and preparing dataset...\")\n",
    "data_splits = data_processor.load_and_prepare_data(validation_split=0.2, test_split=0.1)\n",
    "\n",
    "print(\"‚úÖ Data preparation completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564c8980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéõÔ∏è Class Weight Calculation for Imbalanced Dataset\n",
    "\n",
    "def calculate_strategic_class_weights(y_train, labels, strategy='balanced'):\n",
    "    \"\"\"Calculate class weights with multiple strategies for imbalanced data\"\"\"\n",
    "    \n",
    "    # Count samples per class\n",
    "    unique_labels, counts = np.unique(y_train, return_counts=True)\n",
    "    \n",
    "    strategies = {\n",
    "        'balanced': compute_class_weight('balanced', classes=unique_labels, y=y_train),\n",
    "        'inverse_freq': len(y_train) / (len(unique_labels) * counts),\n",
    "        'sqrt_inverse_freq': np.sqrt(len(y_train) / (len(unique_labels) * counts)),\n",
    "        'log_inverse_freq': np.log(len(y_train) / counts),\n",
    "    }\n",
    "    \n",
    "    class_weights = strategies[strategy]\n",
    "    class_weight_dict = dict(zip(unique_labels, class_weights))\n",
    "    \n",
    "    print(f\"üìä Class Weight Strategy: {strategy}\")\n",
    "    print(f\"üî¢ Weight Range: {class_weights.min():.3f} - {class_weights.max():.3f}\")\n",
    "    \n",
    "    # Visualize class weights\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Class distribution\n",
    "    ax1.bar(range(len(counts)), counts, color='lightblue', alpha=0.7)\n",
    "    ax1.set_title('üìä Original Class Distribution')\n",
    "    ax1.set_xlabel('Class Index')\n",
    "    ax1.set_ylabel('Sample Count')\n",
    "    \n",
    "    # Class weights\n",
    "    ax2.bar(range(len(class_weights)), class_weights, color='orange', alpha=0.7)\n",
    "    ax2.set_title(f'‚öñÔ∏è Class Weights ({strategy})')\n",
    "    ax2.set_xlabel('Class Index')\n",
    "    ax2.set_ylabel('Weight')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return class_weight_dict\n",
    "\n",
    "# Calculate class weights\n",
    "X_train, y_train = data_splits['train']\n",
    "class_weights = calculate_strategic_class_weights(y_train, data_processor.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dfa049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üèóÔ∏è Advanced Model Architecture Factory\n",
    "\n",
    "class PlantDiseaseModelFactory:\n",
    "    \"\"\"Factory for creating state-of-the-art plant disease detection models\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes, input_shape=(224, 224, 3)):\n",
    "        self.num_classes = num_classes\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "    def create_efficient_net_model(self, model_size='B0', fine_tune=True):\n",
    "        \"\"\"Create EfficientNet-based model - excellent for agricultural imagery\"\"\"\n",
    "        \n",
    "        # Load pre-trained EfficientNet\n",
    "        if model_size == 'B0':\n",
    "            base_model = applications.EfficientNetB0(\n",
    "                weights='imagenet',\n",
    "                include_top=False,\n",
    "                input_shape=self.input_shape\n",
    "            )\n",
    "        elif model_size == 'B3':\n",
    "            base_model = applications.EfficientNetB3(\n",
    "                weights='imagenet', \n",
    "                include_top=False,\n",
    "                input_shape=self.input_shape\n",
    "            )\n",
    "        \n",
    "        # Add custom classifier head\n",
    "        model = keras.Sequential([\n",
    "            base_model,\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(512, activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.BatchNormalization(), \n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(self.num_classes, activation='softmax', name='predictions')\n",
    "        ])\n",
    "        \n",
    "        if fine_tune:\n",
    "            # Unfreeze the last few layers for fine-tuning\n",
    "            base_model.trainable = True\n",
    "            for layer in base_model.layers[:-20]:\n",
    "                layer.trainable = False\n",
    "        else:\n",
    "            base_model.trainable = False\n",
    "            \n",
    "        return model\n",
    "    \n",
    "    def create_vision_transformer(self, patch_size=16, num_heads=8, num_layers=6):\n",
    "        \"\"\"Create Vision Transformer model for plant disease detection\"\"\"\n",
    "        \n",
    "        # Vision Transformer implementation\n",
    "        inputs = layers.Input(shape=self.input_shape)\n",
    "        \n",
    "        # Patch extraction\n",
    "        patches = self._extract_patches(inputs, patch_size)\n",
    "        patch_dims = patch_size * patch_size * 3\n",
    "        \n",
    "        # Patch encoding\n",
    "        encoded_patches = layers.Dense(256)(patches)\n",
    "        \n",
    "        # Positional encoding\n",
    "        num_patches = (self.input_shape[0] // patch_size) ** 2\n",
    "        positions = tf.range(start=0, limit=num_patches, delta=1)\n",
    "        position_embedding = layers.Embedding(input_dim=num_patches, output_dim=256)(positions)\n",
    "        encoded_patches = encoded_patches + position_embedding\n",
    "        \n",
    "        # Transformer blocks\n",
    "        for _ in range(num_layers):\n",
    "            # Multi-head attention\n",
    "            attention_output = layers.MultiHeadAttention(\n",
    "                num_heads=num_heads, key_dim=256\n",
    "            )(encoded_patches, encoded_patches)\n",
    "            attention_output = layers.Dropout(0.1)(attention_output)\n",
    "            attention_output = layers.LayerNormalization()(encoded_patches + attention_output)\n",
    "            \n",
    "            # Feed forward\n",
    "            ffn_output = layers.Dense(512, activation='gelu')(attention_output)\n",
    "            ffn_output = layers.Dense(256)(ffn_output)\n",
    "            ffn_output = layers.Dropout(0.1)(ffn_output)\n",
    "            encoded_patches = layers.LayerNormalization()(attention_output + ffn_output)\n",
    "        \n",
    "        # Global average pooling and classification\n",
    "        representation = layers.GlobalAveragePooling1D()(encoded_patches)\n",
    "        features = layers.Dense(512, activation='relu')(representation)\n",
    "        features = layers.Dropout(0.3)(features)\n",
    "        outputs = layers.Dense(self.num_classes, activation='softmax')(features)\n",
    "        \n",
    "        model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        return model\n",
    "    \n",
    "    def _extract_patches(self, images, patch_size):\n",
    "        \"\"\"Extract patches from images\"\"\"\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, patch_size, patch_size, 1],\n",
    "            strides=[1, patch_size, patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches\n",
    "    \n",
    "    def create_hybrid_cnn_transformer(self):\n",
    "        \"\"\"Create hybrid CNN-Transformer model combining both approaches\"\"\"\n",
    "        \n",
    "        # CNN backbone for feature extraction\n",
    "        base_cnn = applications.EfficientNetB0(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=self.input_shape\n",
    "        )\n",
    "        base_cnn.trainable = False\n",
    "        \n",
    "        inputs = layers.Input(shape=self.input_shape)\n",
    "        \n",
    "        # CNN feature extraction\n",
    "        cnn_features = base_cnn(inputs, training=False)\n",
    "        cnn_features = layers.GlobalAveragePooling2D()(cnn_features)\n",
    "        \n",
    "        # Transformer branch\n",
    "        patches = self._extract_patches(inputs, patch_size=32)\n",
    "        patch_embedding = layers.Dense(256)(patches)\n",
    "        \n",
    "        # Single transformer block\n",
    "        attention_output = layers.MultiHeadAttention(num_heads=8, key_dim=256)(\n",
    "            patch_embedding, patch_embedding\n",
    "        )\n",
    "        attention_output = layers.LayerNormalization()(patch_embedding + attention_output)\n",
    "        transformer_features = layers.GlobalAveragePooling1D()(attention_output)\n",
    "        \n",
    "        # Fusion layer\n",
    "        combined_features = layers.Concatenate()([cnn_features, transformer_features])\n",
    "        combined_features = layers.Dense(512, activation='relu')(combined_features)\n",
    "        combined_features = layers.BatchNormalization()(combined_features)\n",
    "        combined_features = layers.Dropout(0.4)(combined_features)\n",
    "        \n",
    "        # Final classification\n",
    "        outputs = layers.Dense(self.num_classes, activation='softmax')(combined_features)\n",
    "        \n",
    "        model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        return model\n",
    "    \n",
    "    def create_ensemble_model(self, models_list):\n",
    "        \"\"\"Create ensemble model from multiple architectures\"\"\"\n",
    "        \n",
    "        inputs = layers.Input(shape=self.input_shape)\n",
    "        outputs = []\n",
    "        \n",
    "        for model in models_list:\n",
    "            model.trainable = False\n",
    "            output = model(inputs)\n",
    "            outputs.append(output)\n",
    "        \n",
    "        # Average ensemble\n",
    "        ensemble_output = layers.Average()(outputs)\n",
    "        \n",
    "        ensemble_model = keras.Model(inputs=inputs, outputs=ensemble_output)\n",
    "        return ensemble_model\n",
    "\n",
    "# Initialize model factory\n",
    "model_factory = PlantDiseaseModelFactory(\n",
    "    num_classes=len(data_processor.class_names), \n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "print(f\"üè≠ Model Factory initialized for {len(data_processor.class_names)} classes\")\n",
    "print(f\"üéØ Input shape: {model_factory.input_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd7bfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ Create and Compare Multiple Model Architectures\n",
    "\n",
    "def create_and_compare_models():\n",
    "    \"\"\"Create multiple model architectures for comparison\"\"\"\n",
    "    \n",
    "    models = {}\n",
    "    \n",
    "    print(\"üî® Building model architectures...\")\n",
    "    \n",
    "    # 1. EfficientNet B0 (Fast, efficient)\n",
    "    print(\"   üì± Creating EfficientNet-B0 (Mobile-friendly)...\")\n",
    "    models['efficientnet_b0'] = model_factory.create_efficient_net_model('B0', fine_tune=True)\n",
    "    \n",
    "    # 2. EfficientNet B3 (Higher accuracy)\n",
    "    print(\"   üî• Creating EfficientNet-B3 (High performance)...\")\n",
    "    models['efficientnet_b3'] = model_factory.create_efficient_net_model('B3', fine_tune=True)\n",
    "    \n",
    "    # 3. Hybrid CNN-Transformer\n",
    "    print(\"   ü§ñ Creating Hybrid CNN-Transformer...\")\n",
    "    models['hybrid_cnn_transformer'] = model_factory.create_hybrid_cnn_transformer()\n",
    "    \n",
    "    # Model summary comparison\n",
    "    print(\"\\nüìä Model Architecture Comparison:\")\n",
    "    for name, model in models.items():\n",
    "        total_params = model.count_params()\n",
    "        trainable_params = sum([keras.backend.count_params(w) for w in model.trainable_weights])\n",
    "        \n",
    "        print(f\"\\nüèóÔ∏è {name.replace('_', ' ').title()}:\")\n",
    "        print(f\"   üìè Total Parameters: {total_params:,}\")\n",
    "        print(f\"   üéØ Trainable Parameters: {trainable_params:,}\")\n",
    "        print(f\"   üíæ Estimated Model Size: {total_params * 4 / (1024**2):.1f} MB\")\n",
    "    \n",
    "    return models\n",
    "\n",
    "# Create model architectures\n",
    "models = create_and_compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28893751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìà Advanced Training Configuration & Callbacks\n",
    "\n",
    "def create_training_callbacks(model_name, monitor='val_accuracy'):\n",
    "    \"\"\"Create comprehensive training callbacks for agricultural AI\"\"\"\n",
    "    \n",
    "    # Paths for this specific model\n",
    "    model_dir = MODELS_DIR / model_name\n",
    "    model_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    callbacks_list = [\n",
    "        # Model checkpointing - save best model\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath=str(model_dir / 'best_model.h5'),\n",
    "            monitor=monitor,\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            mode='max',\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Early stopping - prevent overfitting\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor=monitor,\n",
    "            patience=15,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Learning rate reduction\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=8,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # CSV logging\n",
    "        keras.callbacks.CSVLogger(\n",
    "            filename=str(model_dir / 'training_log.csv'),\n",
    "            append=True\n",
    "        ),\n",
    "        \n",
    "        # TensorBoard logging\n",
    "        keras.callbacks.TensorBoard(\n",
    "            log_dir=str(EXPERIMENTS_DIR / 'tensorboard' / model_name),\n",
    "            histogram_freq=1,\n",
    "            write_graph=True,\n",
    "            write_images=True,\n",
    "            update_freq='epoch'\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    return callbacks_list\n",
    "\n",
    "def compile_model_for_agriculture(model, model_name):\n",
    "    \"\"\"Compile model with agricultural-specific considerations\"\"\"\n",
    "    \n",
    "    # For critical agricultural applications, we prioritize:\n",
    "    # 1. High recall for disease detection (avoid false negatives)\n",
    "    # 2. Calibrated confidence scores\n",
    "    # 3. Robust optimization\n",
    "    \n",
    "    # Custom metrics for agricultural applications\n",
    "    def f1_score(y_true, y_pred):\n",
    "        \"\"\"F1 score metric\"\"\"\n",
    "        y_pred = tf.round(y_pred)\n",
    "        tp = tf.reduce_sum(tf.cast(y_true * y_pred, tf.float32), axis=0)\n",
    "        fp = tf.reduce_sum(tf.cast((1 - y_true) * y_pred, tf.float32), axis=0)\n",
    "        fn = tf.reduce_sum(tf.cast(y_true * (1 - y_pred), tf.float32), axis=0)\n",
    "        \n",
    "        precision = tp / (tp + fp + tf.keras.backend.epsilon())\n",
    "        recall = tp / (tp + fn + tf.keras.backend.epsilon())\n",
    "        f1 = 2 * precision * recall / (precision + recall + tf.keras.backend.epsilon())\n",
    "        \n",
    "        return tf.reduce_mean(f1)\n",
    "    \n",
    "    def recall_score(y_true, y_pred):\n",
    "        \"\"\"Recall score - critical for disease detection\"\"\"\n",
    "        y_pred = tf.round(y_pred)\n",
    "        tp = tf.reduce_sum(tf.cast(y_true * y_pred, tf.float32), axis=0)\n",
    "        fn = tf.reduce_sum(tf.cast(y_true * (1 - y_pred), tf.float32), axis=0)\n",
    "        return tf.reduce_mean(tp / (tp + fn + tf.keras.backend.epsilon()))\n",
    "    \n",
    "    def precision_score(y_true, y_pred):\n",
    "        \"\"\"Precision score\"\"\"\n",
    "        y_pred = tf.round(y_pred)\n",
    "        tp = tf.reduce_sum(tf.cast(y_true * y_pred, tf.float32), axis=0)\n",
    "        fp = tf.reduce_sum(tf.cast((1 - y_true) * y_pred, tf.float32), axis=0)\n",
    "        return tf.reduce_mean(tp / (tp + fp + tf.keras.backend.epsilon()))\n",
    "    \n",
    "    # Focal loss for handling class imbalance\n",
    "    def focal_loss(alpha=0.25, gamma=2.0):\n",
    "        \"\"\"Focal loss to handle class imbalance\"\"\"\n",
    "        def focal_loss_fixed(y_true, y_pred):\n",
    "            y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1 - tf.keras.backend.epsilon())\n",
    "            p_t = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n",
    "            alpha_factor = tf.ones_like(y_true) * alpha\n",
    "            alpha_t = tf.where(tf.equal(y_true, 1), alpha_factor, 1 - alpha_factor)\n",
    "            cross_entropy = -tf.math.log(p_t)\n",
    "            weight = alpha_t * tf.pow((1 - p_t), gamma)\n",
    "            loss = weight * cross_entropy\n",
    "            return tf.reduce_mean(tf.reduce_sum(loss, axis=1))\n",
    "        return focal_loss_fixed\n",
    "    \n",
    "    # Choose optimizer based on model complexity\n",
    "    if 'efficientnet' in model_name.lower():\n",
    "        optimizer = keras.optimizers.AdamW(learning_rate=0.001, weight_decay=0.0001)\n",
    "    else:\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=focal_loss(alpha=0.25, gamma=2.0),\n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            keras.metrics.TopKCategoricalAccuracy(k=3, name='top3_accuracy'),\n",
    "            f1_score,\n",
    "            recall_score,\n",
    "            precision_score\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Model '{model_name}' compiled successfully\")\n",
    "    print(f\"   üéØ Loss: Focal Loss (Œ±=0.25, Œ≥=2.0)\")\n",
    "    print(f\"   üìä Metrics: Accuracy, Top-3, F1, Recall, Precision\")\n",
    "    print(f\"   ‚ö° Optimizer: {optimizer.__class__.__name__}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Compile all models\n",
    "print(\"‚öôÔ∏è Compiling models for agricultural applications...\")\n",
    "for name, model in models.items():\n",
    "    models[name] = compile_model_for_agriculture(model, name)\n",
    "\n",
    "print(\"‚úÖ All models compiled successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3a531b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üèãÔ∏è‚Äç‚ôÇÔ∏è Create TensorFlow Datasets for Training\n",
    "\n",
    "print(\"üîÑ Creating TensorFlow datasets...\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = data_processor.create_tf_dataset(\n",
    "    data_splits['train'][0], \n",
    "    data_splits['train'][1], \n",
    "    training=True\n",
    ")\n",
    "\n",
    "val_dataset = data_processor.create_tf_dataset(\n",
    "    data_splits['val'][0], \n",
    "    data_splits['val'][1], \n",
    "    training=False\n",
    ")\n",
    "\n",
    "test_dataset = data_processor.create_tf_dataset(\n",
    "    data_splits['test'][0], \n",
    "    data_splits['test'][1], \n",
    "    training=False\n",
    ")\n",
    "\n",
    "# Calculate steps per epoch\n",
    "steps_per_epoch = len(data_splits['train'][0]) // data_processor.batch_size\n",
    "validation_steps = len(data_splits['val'][0]) // data_processor.batch_size\n",
    "\n",
    "print(f\"üìä Dataset Statistics:\")\n",
    "print(f\"   üèãÔ∏è Steps per Epoch: {steps_per_epoch}\")\n",
    "print(f\"   üîç Validation Steps: {validation_steps}\")\n",
    "print(f\"   üíø Batch Size: {data_processor.batch_size}\")\n",
    "\n",
    "# Visualize a batch of training data\n",
    "def visualize_training_batch(dataset, class_names, num_images=12):\n",
    "    \"\"\"Visualize a batch of training data with augmentations\"\"\"\n",
    "    \n",
    "    # Get a batch\n",
    "    for images, labels in dataset.take(1):\n",
    "        fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i in range(min(num_images, len(images))):\n",
    "            img = images[i].numpy()\n",
    "            label_idx = tf.argmax(labels[i]).numpy()\n",
    "            label_name = class_names[label_idx]\n",
    "            \n",
    "            axes[i].imshow(img)\n",
    "            axes[i].set_title(f\"{label_name}\", fontsize=10)\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        # Hide extra subplots\n",
    "        for i in range(num_images, len(axes)):\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.suptitle('üå± Training Data with Augmentations', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        break\n",
    "\n",
    "# Visualize training data\n",
    "print(\"üëÄ Visualizing training data with augmentations...\")\n",
    "visualize_training_batch(train_dataset, data_processor.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab20cdfd",
   "metadata": {},
   "source": [
    "# üß≠ Notebook Relocated\n",
    "\n",
    "This notebook has been superseded by a new dedicated EDA notebook and a separate training/evaluation notebook to better align with the project goals:\n",
    "\n",
    "- 01_eda_plant_disease.ipynb ‚Äì Comprehensive EDA with interactive Plotly visuals\n",
    "- 02_training_evaluation.ipynb ‚Äì Model training, evaluation, and calibration\n",
    "\n",
    "You can safely continue using the new notebooks in the `notebooks/` folder."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_engineer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
