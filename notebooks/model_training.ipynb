{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02b939eb",
   "metadata": {},
   "source": [
    "# 🧠 CAPSTONE-LAZARUS: Model Training Pipeline\n",
    "\n",
    "## Advanced Plant Disease Classification Training\n",
    "**State-of-the-art transfer learning with comprehensive evaluation**\n",
    "\n",
    "### 🎯 Training Objectives:\n",
    "- **Multi-Architecture Evaluation**: EfficientNet, ResNet, MobileNet comparisons\n",
    "- **Transfer Learning**: Pre-trained ImageNet → Agricultural fine-tuning\n",
    "- **Balanced Training**: Class-weighted loss for imbalanced dataset\n",
    "- **Advanced Augmentation**: Field condition simulation\n",
    "- **Comprehensive Metrics**: F1, Precision, Recall, Confusion Matrix\n",
    "- **Model Optimization**: Pruning, quantization for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a1911e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📦 Import Essential Libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 🤖 Deep Learning Framework\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, optimizers, callbacks, metrics\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 📊 Interactive Visualizations\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# 🎯 Metrics & Evaluation\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, \n",
    "    f1_score, precision_recall_fscore_support\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# 🔧 Utilities\n",
    "import pickle\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple, Any\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "from data_utils import PlantDiseaseDataLoader\n",
    "from model_factory import ModelFactory\n",
    "\n",
    "# 🎨 Configure Plotly\n",
    "px.defaults.template = \"plotly_white\"\n",
    "\n",
    "# 🔧 TensorFlow Configuration\n",
    "tf.config.experimental.enable_tensor_float_32_execution(False)\n",
    "print(f\"🚀 TensorFlow version: {tf.__version__}\")\n",
    "print(f\"🖥️  GPU Available: {tf.config.list_physical_devices('GPU')}\")\n",
    "print(f\"📂 Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57193136",
   "metadata": {},
   "source": [
    "## 📊 Load Dataset & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699a84e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📂 Load Dataset Splits from EDA\n",
    "data_dir = \"../data\"\n",
    "models_dir = Path(\"../models\")\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Load pre-computed splits and weights\n",
    "try:\n",
    "    split_info = np.load('../models/dataset_splits.npy', allow_pickle=True).item()\n",
    "    class_weights = np.load('../models/class_weights.npy', allow_pickle=True).item()\n",
    "    \n",
    "    X_train = split_info['train_paths']\n",
    "    y_train = split_info['train_labels']\n",
    "    X_val = split_info['val_paths']\n",
    "    y_val = split_info['val_labels']\n",
    "    X_test = split_info['test_paths']\n",
    "    y_test = split_info['test_labels']\n",
    "    class_names = split_info['class_names']\n",
    "    label_mapping = split_info['label_mapping']\n",
    "    \n",
    "    print(\"✅ Loaded pre-computed dataset splits and class weights\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"⚠️  Pre-computed splits not found. Running EDA first...\")\n",
    "    # Fallback: create splits\n",
    "    loader = PlantDiseaseDataLoader(data_dir, img_size=(224, 224), batch_size=32)\n",
    "    dataset_stats = loader.scan_dataset()\n",
    "    (X_train, y_train), (X_val, y_val), (X_test, y_test) = loader.create_balanced_splits()\n",
    "    class_weights = loader.compute_class_weights(y_train)\n",
    "    class_names = loader.class_names\n",
    "\n",
    "num_classes = len(class_names)\n",
    "print(f\"\\n📊 Dataset Configuration:\")\n",
    "print(f\"   🚂 Training: {len(X_train):,} images\")\n",
    "print(f\"   🔍 Validation: {len(X_val):,} images\")\n",
    "print(f\"   🧪 Testing: {len(X_test):,} images\")\n",
    "print(f\"   🏷️  Classes: {num_classes}\")\n",
    "print(f\"   ⚖️  Using class weights: {len(class_weights)} weights computed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c35a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔧 Create TensorFlow Datasets with Optimizations\n",
    "def create_optimized_dataset(paths: List[str], labels: List[int], \n",
    "                           batch_size: int = 32, is_training: bool = True,\n",
    "                           img_size: Tuple[int, int] = (224, 224)) -> tf.data.Dataset:\n",
    "    \"\"\"Create optimized TensorFlow dataset with augmentation.\"\"\"\n",
    "    \n",
    "    def load_and_preprocess(path, label):\n",
    "        # Load image\n",
    "        image = tf.io.read_file(path)\n",
    "        image = tf.image.decode_image(image, channels=3, expand_animations=False)\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        \n",
    "        # Resize\n",
    "        image = tf.image.resize(image, img_size)\n",
    "        \n",
    "        # Normalize to [0, 1]\n",
    "        image = image / 255.0\n",
    "        \n",
    "        # Augmentation for training only\n",
    "        if is_training:\n",
    "            # Random flips\n",
    "            image = tf.image.random_flip_left_right(image)\n",
    "            image = tf.image.random_flip_up_down(image)\n",
    "            \n",
    "            # Color augmentation\n",
    "            image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "            image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "            image = tf.image.random_hue(image, max_delta=0.1)\n",
    "            image = tf.image.random_saturation(image, lower=0.8, upper=1.2)\n",
    "            \n",
    "            # Random rotation (approximate using cropping)\n",
    "            image = tf.image.random_crop(image, size=[int(img_size[0]*0.9), int(img_size[1]*0.9), 3])\n",
    "            image = tf.image.resize(image, img_size)\n",
    "        \n",
    "        # Final normalization (ImageNet stats)\n",
    "        image = (image - [0.485, 0.456, 0.406]) / [0.229, 0.224, 0.225]\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    # Create dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    \n",
    "    if is_training:\n",
    "        dataset = dataset.shuffle(buffer_size=min(len(paths), 10000))\n",
    "        dataset = dataset.repeat()  # Repeat for multiple epochs\n",
    "    \n",
    "    dataset = dataset.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# 📊 Create optimized datasets\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "train_dataset = create_optimized_dataset(X_train, y_train, BATCH_SIZE, is_training=True, img_size=IMG_SIZE)\n",
    "val_dataset = create_optimized_dataset(X_val, y_val, BATCH_SIZE, is_training=False, img_size=IMG_SIZE)\n",
    "test_dataset = create_optimized_dataset(X_test, y_test, BATCH_SIZE, is_training=False, img_size=IMG_SIZE)\n",
    "\n",
    "print(\"✅ TensorFlow datasets created with optimizations\")\n",
    "print(f\"   🚂 Training batches per epoch: {len(X_train) // BATCH_SIZE}\")\n",
    "print(f\"   🔍 Validation batches: {len(X_val) // BATCH_SIZE}\")\n",
    "print(f\"   🧪 Test batches: {len(X_test) // BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec1607d",
   "metadata": {},
   "source": [
    "## 🏗️ Model Architecture Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361c85e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🏭 Initialize Model Factory\n",
    "factory = ModelFactory(input_shape=(224, 224, 3), num_classes=num_classes, use_mixed_precision=True)\n",
    "\n",
    "# 🎯 Define Model Architectures to Evaluate\n",
    "architectures_to_test = [\n",
    "    {\n",
    "        'name': 'EfficientNetV2-B0',\n",
    "        'arch': 'efficientnet_v2_b0',\n",
    "        'description': '🥇 Best accuracy-efficiency balance',\n",
    "        'target_size': '~15MB',\n",
    "        'expected_accuracy': '0.85+'\n",
    "    },\n",
    "    {\n",
    "        'name': 'MobileNetV3-Large',\n",
    "        'arch': 'mobilenet_v3_large',\n",
    "        'description': '📱 Optimized for mobile deployment',\n",
    "        'target_size': '~10MB',\n",
    "        'expected_accuracy': '0.82+'\n",
    "    },\n",
    "    {\n",
    "        'name': 'ResNet50',\n",
    "        'arch': 'resnet50',\n",
    "        'description': '🏗️ Reliable baseline performance',\n",
    "        'target_size': '~25MB',\n",
    "        'expected_accuracy': '0.83+'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Custom CNN',\n",
    "        'arch': 'custom_cnn',\n",
    "        'description': '🎨 Lightweight custom architecture',\n",
    "        'target_size': '~5MB',\n",
    "        'expected_accuracy': '0.78+'\n",
    "    }\n",
    "]\n",
    "\n",
    "# 📊 Display Architecture Comparison Table\n",
    "arch_df = pd.DataFrame(architectures_to_test)\n",
    "print(\"🏗️ Architecture Comparison:\")\n",
    "print(\"=\" * 80)\n",
    "for _, row in arch_df.iterrows():\n",
    "    print(f\"{row['name']:20} | {row['description']:35} | {row['target_size']:8} | {row['expected_accuracy']}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 🎯 Select primary architecture for full training\n",
    "PRIMARY_ARCHITECTURE = 'efficientnet_v2_b0'\n",
    "print(f\"\\n🎯 Selected primary architecture: {PRIMARY_ARCHITECTURE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906cec23",
   "metadata": {},
   "source": [
    "## 🧠 Model Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d55d328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔧 Training Configuration\n",
    "TRAINING_CONFIG = {\n",
    "    'epochs': 50,\n",
    "    'initial_learning_rate': 1e-3,\n",
    "    'min_learning_rate': 1e-7,\n",
    "    'patience_early_stop': 15,\n",
    "    'patience_lr_reduce': 8,\n",
    "    'lr_reduction_factor': 0.2,\n",
    "    'validation_freq': 1,\n",
    "    'save_best_only': True,\n",
    "    'monitor_metric': 'val_f1_score'\n",
    "}\n",
    "\n",
    "print(\"⚙️ Training Configuration:\")\n",
    "for key, value in TRAINING_CONFIG.items():\n",
    "    print(f\"   • {key}: {value}\")\n",
    "\n",
    "# 📊 Custom F1 Score Metric\n",
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.precision = tf.keras.metrics.Precision()\n",
    "        self.recall = tf.keras.metrics.Recall()\n",
    "    \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "    \n",
    "    def result(self):\n",
    "        p = self.precision.result()\n",
    "        r = self.recall.result()\n",
    "        return 2 * ((p * r) / (p + r + tf.keras.backend.epsilon()))\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.precision.reset_state()\n",
    "        self.recall.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414d99ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🏗️ Create and Compile Model\n",
    "def create_and_compile_model(architecture: str, num_classes: int, \n",
    "                           learning_rate: float = 1e-3) -> tf.keras.Model:\n",
    "    \"\"\"Create and compile model with optimized settings.\"\"\"\n",
    "    \n",
    "    # Create model\n",
    "    model = factory.get_model(architecture, dropout_rate=0.3, freeze_backbone=False)\n",
    "    \n",
    "    # Optimizer with learning rate scheduling\n",
    "    optimizer = tf.keras.optimizers.AdamW(\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=1e-4,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "        epsilon=1e-7\n",
    "    )\n",
    "    \n",
    "    # Compile with comprehensive metrics\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            tf.keras.metrics.TopKCategoricalAccuracy(k=3, name='top_3_accuracy'),\n",
    "            tf.keras.metrics.Precision(name='precision'),\n",
    "            tf.keras.metrics.Recall(name='recall'),\n",
    "            F1Score()\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 🎯 Create primary model\n",
    "print(f\"🏗️ Creating {PRIMARY_ARCHITECTURE} model...\")\n",
    "model = create_and_compile_model(PRIMARY_ARCHITECTURE, num_classes, TRAINING_CONFIG['initial_learning_rate'])\n",
    "\n",
    "# 📊 Model Summary\n",
    "print(\"\\n📋 Model Architecture:\")\n",
    "model.summary()\n",
    "\n",
    "# 📈 Count parameters\n",
    "total_params = model.count_params()\n",
    "trainable_params = sum([tf.keras.backend.count_params(layer) for layer in model.trainable_weights])\n",
    "\n",
    "print(f\"\\n📊 Model Statistics:\")\n",
    "print(f\"   • Total parameters: {total_params:,}\")\n",
    "print(f\"   • Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"   • Non-trainable parameters: {total_params - trainable_params:,}\")\n",
    "print(f\"   • Estimated size: ~{total_params * 4 / (1024*1024):.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a24cb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔄 Advanced Callbacks Setup\n",
    "def create_callbacks(model_name: str, config: Dict[str, Any]) -> List[tf.keras.callbacks.Callback]:\n",
    "    \"\"\"Create comprehensive training callbacks.\"\"\"\n",
    "    \n",
    "    callbacks_list = []\n",
    "    \n",
    "    # 💾 Model Checkpoint - Save best model\n",
    "    checkpoint_path = f\"../models/{model_name}_best.h5\"\n",
    "    callbacks_list.append(\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=checkpoint_path,\n",
    "            monitor=config['monitor_metric'],\n",
    "            save_best_only=config['save_best_only'],\n",
    "            save_weights_only=False,\n",
    "            mode='max',\n",
    "            verbose=1\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # ⏹️ Early Stopping\n",
    "    callbacks_list.append(\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=config['monitor_metric'],\n",
    "            patience=config['patience_early_stop'],\n",
    "            mode='max',\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # 📉 Learning Rate Scheduler\n",
    "    callbacks_list.append(\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=config['monitor_metric'],\n",
    "            factor=config['lr_reduction_factor'],\n",
    "            patience=config['patience_lr_reduce'],\n",
    "            min_lr=config['min_learning_rate'],\n",
    "            mode='max',\n",
    "            verbose=1\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # 📊 TensorBoard Logging\n",
    "    log_dir = f\"../models/logs/{model_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    callbacks_list.append(\n",
    "        tf.keras.callbacks.TensorBoard(\n",
    "            log_dir=log_dir,\n",
    "            histogram_freq=1,\n",
    "            write_graph=True,\n",
    "            write_images=True,\n",
    "            update_freq='epoch'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # 🎯 Custom Progress Callback\n",
    "    class TrainingProgressCallback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs=None):\n",
    "            if logs:\n",
    "                print(f\"\\n📊 Epoch {epoch + 1} Summary:\")\n",
    "                print(f\"   • Training Accuracy: {logs.get('accuracy', 0):.4f}\")\n",
    "                print(f\"   • Validation Accuracy: {logs.get('val_accuracy', 0):.4f}\")\n",
    "                print(f\"   • Training F1: {logs.get('f1_score', 0):.4f}\")\n",
    "                print(f\"   • Validation F1: {logs.get('val_f1_score', 0):.4f}\")\n",
    "                print(f\"   • Learning Rate: {logs.get('lr', 0):.2e}\")\n",
    "    \n",
    "    callbacks_list.append(TrainingProgressCallback())\n",
    "    \n",
    "    return callbacks_list\n",
    "\n",
    "# 🔄 Create callbacks\n",
    "model_name = f\"{PRIMARY_ARCHITECTURE}_plant_disease\"\n",
    "training_callbacks = create_callbacks(model_name, TRAINING_CONFIG)\n",
    "\n",
    "print(f\"✅ Created {len(training_callbacks)} training callbacks\")\n",
    "print(f\"   • Model checkpoint: ../models/{model_name}_best.h5\")\n",
    "print(f\"   • TensorBoard logs: ../models/logs/{model_name}_*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8871b283",
   "metadata": {},
   "source": [
    "## 🚂 Execute Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a6e8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚀 Start Training Process\n",
    "print(\"🚂 Starting model training...\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"🏗️ Architecture: {PRIMARY_ARCHITECTURE}\")\n",
    "print(f\"📊 Training samples: {len(X_train):,}\")\n",
    "print(f\"🔍 Validation samples: {len(X_val):,}\")\n",
    "print(f\"⏱️ Max epochs: {TRAINING_CONFIG['epochs']}\")\n",
    "print(f\"🎯 Batch size: {BATCH_SIZE}\")\n",
    "print(f\"⚖️ Using class weights: Yes\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calculate steps per epoch\n",
    "steps_per_epoch = len(X_train) // BATCH_SIZE\n",
    "validation_steps = len(X_val) // BATCH_SIZE\n",
    "\n",
    "# 🏋️ Train the model\n",
    "start_time = datetime.now()\n",
    "\n",
    "try:\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=TRAINING_CONFIG['epochs'],\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=val_dataset,\n",
    "        validation_steps=validation_steps,\n",
    "        class_weight=class_weights,\n",
    "        callbacks=training_callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    training_time = datetime.now() - start_time\n",
    "    \n",
    "    print(f\"\\n✅ Training completed successfully!\")\n",
    "    print(f\"⏱️ Total training time: {training_time}\")\n",
    "    print(f\"📈 Final training accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "    print(f\"🔍 Final validation accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
    "    print(f\"🎯 Final validation F1: {history.history['val_f1_score'][-1]:.4f}\")\n",
    "    \n",
    "    # 💾 Save training history\n",
    "    history_path = f\"../models/{model_name}_history.json\"\n",
    "    with open(history_path, 'w') as f:\n",
    "        json.dump({\n",
    "            'history': {k: [float(x) for x in v] for k, v in history.history.items()},\n",
    "            'config': TRAINING_CONFIG,\n",
    "            'training_time': str(training_time),\n",
    "            'architecture': PRIMARY_ARCHITECTURE,\n",
    "            'total_params': int(total_params),\n",
    "            'trainable_params': int(trainable_params)\n",
    "        }, f, indent=2)\n",
    "    \n",
    "    print(f\"💾 Training history saved: {history_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Training failed: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576dc550",
   "metadata": {},
   "source": [
    "## 📊 Training Analysis & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260de666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📈 Interactive Training History Visualization\n",
    "def plot_training_history(history_dict: Dict[str, List[float]]) -> None:\n",
    "    \"\"\"Create comprehensive training history plots.\"\"\"\n",
    "    \n",
    "    # Create subplots\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=('📈 Accuracy', '📉 Loss', '🎯 F1 Score', '📊 Learning Rate'),\n",
    "        specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "               [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
    "    )\n",
    "    \n",
    "    epochs = list(range(1, len(history_dict['accuracy']) + 1))\n",
    "    \n",
    "    # Accuracy plot\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=epochs, y=history_dict['accuracy'], name='Training Accuracy', \n",
    "                  line=dict(color='blue'), mode='lines+markers'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=epochs, y=history_dict['val_accuracy'], name='Validation Accuracy', \n",
    "                  line=dict(color='red'), mode='lines+markers'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Loss plot\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=epochs, y=history_dict['loss'], name='Training Loss', \n",
    "                  line=dict(color='blue'), mode='lines+markers'),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=epochs, y=history_dict['val_loss'], name='Validation Loss', \n",
    "                  line=dict(color='red'), mode='lines+markers'),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # F1 Score plot\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=epochs, y=history_dict['f1_score'], name='Training F1', \n",
    "                  line=dict(color='green'), mode='lines+markers'),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=epochs, y=history_dict['val_f1_score'], name='Validation F1', \n",
    "                  line=dict(color='orange'), mode='lines+markers'),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # Learning Rate plot\n",
    "    if 'lr' in history_dict:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=epochs, y=history_dict['lr'], name='Learning Rate', \n",
    "                      line=dict(color='purple'), mode='lines+markers'),\n",
    "            row=2, col=2\n",
    "        )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        title_text=f\"🧠 {PRIMARY_ARCHITECTURE} Training History Analysis\",\n",
    "        title_x=0.5,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    # Update y-axes\n",
    "    fig.update_yaxes(title_text=\"Accuracy\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Loss\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"F1 Score\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Learning Rate\", type=\"log\", row=2, col=2)\n",
    "    \n",
    "    # Update x-axes\n",
    "    fig.update_xaxes(title_text=\"Epoch\", row=2, col=1)\n",
    "    fig.update_xaxes(title_text=\"Epoch\", row=2, col=2)\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "# 📊 Plot training history\n",
    "if 'history' in locals():\n",
    "    plot_training_history(history.history)\n",
    "    \n",
    "    # 📈 Performance Summary\n",
    "    best_val_acc = max(history.history['val_accuracy'])\n",
    "    best_val_f1 = max(history.history['val_f1_score'])\n",
    "    final_lr = history.history['lr'][-1] if 'lr' in history.history else 'N/A'\n",
    "    \n",
    "    print(f\"\\n🏆 Training Performance Summary:\")\n",
    "    print(f\"   • Best Validation Accuracy: {best_val_acc:.4f}\")\n",
    "    print(f\"   • Best Validation F1 Score: {best_val_f1:.4f}\")\n",
    "    print(f\"   • Final Learning Rate: {final_lr}\")\n",
    "    print(f\"   • Total Epochs Completed: {len(history.history['accuracy'])}\")\n",
    "else:\n",
    "    print(\"⚠️ No training history available to plot\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
