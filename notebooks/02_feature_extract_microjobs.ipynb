{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca6e9265",
   "metadata": {},
   "source": [
    "# üî• Micro-Job Feature Extraction Pipeline\n",
    "\n",
    "**Mission**: Eliminate training bottlenecks with resumable feature caching  \n",
    "**Target**: 4GB VRAM, 64 images per job, <2min per job  \n",
    "**Strategy**: EfficientNet-B0 encoder ‚Üí float16 NPZ cache ‚Üí head-only training\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Pipeline Overview\n",
    "\n",
    "1. **Job Queue Creation**: Split dataset into 64-image chunks\n",
    "2. **Feature Extraction**: Process jobs with encoder (batch_size=8)\n",
    "3. **Feature Caching**: Save as `features/encoder_*/img_*.npz` (float16)\n",
    "4. **Manifest Generation**: Create `features/manifest_features.v001.csv`\n",
    "5. **Resume Logic**: Skip completed jobs via `.done` files\n",
    "\n",
    "### üìä Resource Targets\n",
    "- **VRAM**: <2.5GB peak (within 4GB constraint)\n",
    "- **Speed**: 64 images in <2 minutes\n",
    "- **Storage**: ~50MB per 1000 images (float16 compression)\n",
    "- **Quality**: Equivalent to full training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7397f3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Setup & Imports\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Project imports\n",
    "sys.path.append('../src')\n",
    "from data_utils import ImageFolderAlb\n",
    "\n",
    "# üéÆ Device & Memory Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"üöÄ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Running on CPU - feature extraction will be slower\")\n",
    "\n",
    "print(f\"üîß PyTorch: {torch.__version__}\")\n",
    "print(f\"üìÅ Working dir: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42c3c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚öôÔ∏è Configuration\n",
    "CONFIG = {\n",
    "    # Paths\n",
    "    'data_dir': '../data',\n",
    "    'features_dir': '../features',\n",
    "    'encoder_name': 'efficientnet_b0',\n",
    "    \n",
    "    # Job settings (4GB VRAM optimized)\n",
    "    'job_size': 64,          # Images per job\n",
    "    'batch_size': 8,         # Processing batch (VRAM constraint)\n",
    "    'img_size': 224,         # Input resolution\n",
    "    'feature_dtype': 'float16',  # Memory compression\n",
    "    \n",
    "    # Feature extraction\n",
    "    'use_global_pool': True,     # Extract global features\n",
    "    'extract_spatial': False,    # Skip spatial for now (head-only training)\n",
    "    'normalize_features': True,  # L2 normalize\n",
    "    \n",
    "    # Performance\n",
    "    'num_workers': 4,        # DataLoader workers\n",
    "    'pin_memory': True,      # GPU transfer optimization\n",
    "    'prefetch_factor': 2,    # Async data loading\n",
    "}\n",
    "\n",
    "print(\"üéØ MICRO-JOB CONFIGURATION:\")\n",
    "print(f\"   üìä Job size: {CONFIG['job_size']} images\")\n",
    "print(f\"   üé¨ Batch size: {CONFIG['batch_size']} (VRAM-safe)\")\n",
    "print(f\"   üìê Image size: {CONFIG['img_size']}px\")\n",
    "print(f\"   üóúÔ∏è Feature dtype: {CONFIG['feature_dtype']}\")\n",
    "print(f\"   üèóÔ∏è Encoder: {CONFIG['encoder_name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e88835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Dataset Scanning & Job Queue Creation\n",
    "\n",
    "def scan_dataset(data_dir: str) -> pd.DataFrame:\n",
    "    \"\"\"Scan dataset and create image manifest\"\"\"\n",
    "    print(f\"üîç Scanning dataset: {data_dir}\")\n",
    "    \n",
    "    data_path = Path(data_dir)\n",
    "    if not data_path.exists():\n",
    "        raise FileNotFoundError(f\"Data directory not found: {data_dir}\")\n",
    "    \n",
    "    # Collect all images\n",
    "    images = []\n",
    "    for class_dir in data_path.iterdir():\n",
    "        if not class_dir.is_dir():\n",
    "            continue\n",
    "            \n",
    "        class_name = class_dir.name\n",
    "        print(f\"   üìÅ Processing class: {class_name}\")\n",
    "        \n",
    "        for img_file in class_dir.glob('*'):\n",
    "            if img_file.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp']:\n",
    "                images.append({\n",
    "                    'image_path': str(img_file),\n",
    "                    'class_name': class_name,\n",
    "                    'image_id': f\"{class_name}_{img_file.stem}\",\n",
    "                    'file_size': img_file.stat().st_size\n",
    "                })\n",
    "    \n",
    "    df = pd.DataFrame(images)\n",
    "    print(f\"\\n‚úÖ Dataset scan complete:\")\n",
    "    print(f\"   üñºÔ∏è Total images: {len(df):,}\")\n",
    "    print(f\"   üè∑Ô∏è Classes: {df['class_name'].nunique()}\")\n",
    "    print(f\"   üíæ Total size: {df['file_size'].sum() / 1e9:.2f}GB\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_job_queue(image_df: pd.DataFrame, job_size: int = 64) -> pd.DataFrame:\n",
    "    \"\"\"Split images into job chunks for micro-job processing\"\"\"\n",
    "    print(f\"\\nüìã Creating job queue (job_size={job_size})...\")\n",
    "    \n",
    "    # Shuffle for balanced jobs across classes\n",
    "    shuffled_df = image_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    # Create job chunks\n",
    "    jobs = []\n",
    "    for i in range(0, len(shuffled_df), job_size):\n",
    "        job_images = shuffled_df.iloc[i:i+job_size]\n",
    "        \n",
    "        jobs.append({\n",
    "            'job_id': len(jobs),\n",
    "            'image_paths': ','.join(job_images['image_path'].tolist()),\n",
    "            'image_ids': ','.join(job_images['image_id'].tolist()),\n",
    "            'num_images': len(job_images),\n",
    "            'classes': ','.join(job_images['class_name'].unique()),\n",
    "            'status': 'pending',\n",
    "            'created_at': datetime.now().isoformat()\n",
    "        })\n",
    "    \n",
    "    job_df = pd.DataFrame(jobs)\n",
    "    print(f\"‚úÖ Job queue created: {len(job_df)} jobs\")\n",
    "    print(f\"   üìä Average job size: {job_df['num_images'].mean():.1f} images\")\n",
    "    print(f\"   üéØ Estimated time: {len(job_df) * 2:.0f} minutes (2min/job)\")\n",
    "    \n",
    "    return job_df\n",
    "\n",
    "# Execute dataset scanning\n",
    "image_manifest = scan_dataset(CONFIG['data_dir'])\n",
    "job_queue = create_job_queue(image_manifest, CONFIG['job_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b1d6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üèóÔ∏è Feature Extraction Setup\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    \"\"\"Lightweight feature extractor with global pooling\"\"\"\n",
    "    \n",
    "    def __init__(self, encoder_name: str = 'efficientnet_b0', pretrained: bool = True):\n",
    "        super().__init__()\n",
    "        self.encoder_name = encoder_name\n",
    "        \n",
    "        # Load pretrained encoder\n",
    "        self.backbone = timm.create_model(\n",
    "            encoder_name, \n",
    "            pretrained=pretrained,\n",
    "            num_classes=0,  # Remove classifier head\n",
    "            global_pool='avg'  # Global average pooling\n",
    "        )\n",
    "        \n",
    "        # Get feature dimensions\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.randn(1, 3, 224, 224)\n",
    "            dummy_output = self.backbone(dummy_input)\n",
    "            self.feature_dim = dummy_output.shape[1]\n",
    "        \n",
    "        print(f\"üèóÔ∏è Feature extractor: {encoder_name}\")\n",
    "        print(f\"   üìê Feature dim: {self.feature_dim}\")\n",
    "        print(f\"   üíæ Parameters: {sum(p.numel() for p in self.parameters()):,}\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Extract global features\"\"\"\n",
    "        features = self.backbone(x)  # [B, feature_dim]\n",
    "        return features\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    \"\"\"Simple dataset for feature extraction\"\"\"\n",
    "    \n",
    "    def __init__(self, image_paths: List[str], transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        \n",
    "        # Load image\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error loading {img_path}: {e}\")\n",
    "            # Return black image as fallback\n",
    "            image = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, img_path\n",
    "\n",
    "# Initialize feature extractor\n",
    "feature_extractor = FeatureExtractor(CONFIG['encoder_name']).to(device)\n",
    "feature_extractor.eval()\n",
    "\n",
    "# Define transforms (minimal - just resize & normalize)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((CONFIG['img_size'], CONFIG['img_size'])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(f\"‚úÖ Feature extraction setup complete\")\n",
    "print(f\"   üéØ Ready for {CONFIG['job_size']}-image micro-jobs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfb3a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî• Core Job Execution Function\n",
    "\n",
    "def run_feature_job(job_id: int, job_queue: pd.DataFrame, force_rerun: bool = False) -> bool:\n",
    "    \"\"\"Execute single feature extraction job\"\"\"\n",
    "    \n",
    "    if job_id >= len(job_queue):\n",
    "        print(f\"‚ùå Job ID {job_id} out of range (max: {len(job_queue)-1})\")\n",
    "        return False\n",
    "    \n",
    "    job = job_queue.iloc[job_id]\n",
    "    \n",
    "    # Create output directories\n",
    "    features_dir = Path(CONFIG['features_dir'])\n",
    "    encoder_dir = features_dir / f\"encoder_{CONFIG['encoder_name']}\"\n",
    "    encoder_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Check if job already completed\n",
    "    done_file = features_dir / f\"_job_{job_id:04d}_{int(time.time())}.done\"\n",
    "    existing_done = list(features_dir.glob(f\"_job_{job_id:04d}_*.done\"))\n",
    "    \n",
    "    if existing_done and not force_rerun:\n",
    "        print(f\"‚úÖ Job {job_id} already completed: {existing_done[0].name}\")\n",
    "        return True\n",
    "    \n",
    "    print(f\"\\nüöÄ Starting job {job_id}/{len(job_queue)-1}\")\n",
    "    print(f\"   üìä Images: {job['num_images']}\")\n",
    "    print(f\"   üè∑Ô∏è Classes: {job['classes']}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Parse image paths\n",
    "        image_paths = job['image_paths'].split(',')\n",
    "        image_ids = job['image_ids'].split(',')\n",
    "        \n",
    "        # Create dataset and dataloader\n",
    "        dataset = ImageDataset(image_paths, transform=transform)\n",
    "        dataloader = DataLoader(\n",
    "            dataset, \n",
    "            batch_size=CONFIG['batch_size'],\n",
    "            shuffle=False,\n",
    "            num_workers=CONFIG['num_workers'],\n",
    "            pin_memory=CONFIG['pin_memory'],\n",
    "            prefetch_factor=CONFIG['prefetch_factor']\n",
    "        )\n",
    "        \n",
    "        # Extract features\n",
    "        all_features = []\n",
    "        all_paths = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_images, batch_paths in tqdm(dataloader, \n",
    "                                                 desc=f\"Job {job_id}\", \n",
    "                                                 leave=False):\n",
    "                batch_images = batch_images.to(device, non_blocking=True)\n",
    "                \n",
    "                # Extract features\n",
    "                features = feature_extractor(batch_images)  # [B, feature_dim]\n",
    "                \n",
    "                # Normalize if requested\n",
    "                if CONFIG['normalize_features']:\n",
    "                    features = torch.nn.functional.normalize(features, p=2, dim=1)\n",
    "                \n",
    "                # Convert to numpy and compress to float16\n",
    "                features_np = features.cpu().numpy().astype(CONFIG['feature_dtype'])\n",
    "                \n",
    "                all_features.append(features_np)\n",
    "                all_paths.extend(batch_paths)\n",
    "        \n",
    "        # Concatenate all features\n",
    "        all_features = np.concatenate(all_features, axis=0)\n",
    "        \n",
    "        print(f\"   ‚úÖ Extracted: {all_features.shape} features\")\n",
    "        \n",
    "        # Save features individually\n",
    "        saved_count = 0\n",
    "        for i, (img_path, img_id) in enumerate(zip(all_paths, image_ids)):\n",
    "            feature_file = encoder_dir / f\"{img_id}.npz\"\n",
    "            \n",
    "            np.savez_compressed(\n",
    "                feature_file,\n",
    "                features=all_features[i],\n",
    "                image_path=img_path,\n",
    "                image_id=img_id,\n",
    "                encoder_name=CONFIG['encoder_name'],\n",
    "                extraction_time=datetime.now().isoformat()\n",
    "            )\n",
    "            saved_count += 1\n",
    "        \n",
    "        # Create completion marker\n",
    "        job_metadata = {\n",
    "            'job_id': job_id,\n",
    "            'num_images': len(image_paths),\n",
    "            'feature_shape': list(all_features.shape),\n",
    "            'processing_time': time.time() - start_time,\n",
    "            'encoder_name': CONFIG['encoder_name'],\n",
    "            'config': CONFIG,\n",
    "            'completed_at': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        with open(done_file, 'w') as f:\n",
    "            json.dump(job_metadata, f, indent=2)\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"‚úÖ Job {job_id} completed: {saved_count} features saved in {elapsed:.1f}s\")\n",
    "        print(f\"   üíæ Output: {encoder_dir}/\")\n",
    "        print(f\"   üèÅ Done marker: {done_file.name}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Job {job_id} failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "print(\"üî• Job execution function ready\")\n",
    "print(\"   Usage: run_feature_job(job_id, job_queue)\")\n",
    "print(\"   Target: <2 minutes per 64-image job\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6527c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ TEST: Single Job Execution\n",
    "# Run this cell to test the pipeline with job 0\n",
    "\n",
    "TEST_JOB_ID = 0\n",
    "\n",
    "print(f\"üß™ Testing job execution with job {TEST_JOB_ID}\")\n",
    "print(f\"Expected: {job_queue.iloc[TEST_JOB_ID]['num_images']} images processed\")\n",
    "\n",
    "# Clear GPU memory before test\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"üßπ GPU memory cleared\")\n",
    "\n",
    "# Run test job\n",
    "success = run_feature_job(TEST_JOB_ID, job_queue, force_rerun=True)\n",
    "\n",
    "if success:\n",
    "    # Verify outputs\n",
    "    encoder_dir = Path(CONFIG['features_dir']) / f\"encoder_{CONFIG['encoder_name']}\"\n",
    "    feature_files = list(encoder_dir.glob('*.npz'))\n",
    "    done_files = list(Path(CONFIG['features_dir']).glob(f'_job_{TEST_JOB_ID:04d}_*.done'))\n",
    "    \n",
    "    print(f\"\\n‚úÖ TEST RESULTS:\")\n",
    "    print(f\"   üìÅ Feature files created: {len(feature_files)}\")\n",
    "    print(f\"   üèÅ Done files created: {len(done_files)}\")\n",
    "    \n",
    "    # Test loading a feature file\n",
    "    if feature_files:\n",
    "        test_feature = np.load(feature_files[0])\n",
    "        print(f\"   üß™ Sample feature shape: {test_feature['features'].shape}\")\n",
    "        print(f\"   üóúÔ∏è Feature dtype: {test_feature['features'].dtype}\")\n",
    "        \n",
    "        # Check memory usage\n",
    "        feature_size = test_feature['features'].nbytes\n",
    "        total_estimated = feature_size * len(image_manifest) / 1e6\n",
    "        print(f\"   üíæ Per-feature size: {feature_size} bytes\")\n",
    "        print(f\"   üìä Estimated total: {total_estimated:.1f}MB for full dataset\")\n",
    "        \n",
    "    print(f\"\\nüéØ Test job completed successfully!\")\n",
    "else:\n",
    "    print(f\"‚ùå Test job failed - check error messages above\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669221a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üè≠ Batch Job Execution (Full Pipeline)\n",
    "# WARNING: This will process ALL jobs - use for full feature extraction\n",
    "\n",
    "def run_all_jobs(job_queue: pd.DataFrame, max_jobs: int = None, \n",
    "                 start_job: int = 0) -> Dict:\n",
    "    \"\"\"Execute all feature extraction jobs with progress tracking\"\"\"\n",
    "    \n",
    "    total_jobs = len(job_queue)\n",
    "    if max_jobs:\n",
    "        total_jobs = min(total_jobs, max_jobs)\n",
    "    \n",
    "    print(f\"üè≠ BATCH JOB EXECUTION\")\n",
    "    print(f\"   üìä Total jobs: {total_jobs}\")\n",
    "    print(f\"   üéØ Estimated time: {total_jobs * 2:.0f} minutes\")\n",
    "    print(f\"   üíæ Estimated storage: {total_jobs * CONFIG['job_size'] * 0.05:.1f}MB\")\n",
    "    \n",
    "    results = {\n",
    "        'completed_jobs': [],\n",
    "        'failed_jobs': [],\n",
    "        'total_time': 0,\n",
    "        'total_features': 0\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for job_id in tqdm(range(start_job, min(start_job + total_jobs, len(job_queue))), \n",
    "                       desc=\"Processing jobs\"):\n",
    "        \n",
    "        job_start = time.time()\n",
    "        success = run_feature_job(job_id, job_queue)\n",
    "        job_time = time.time() - job_start\n",
    "        \n",
    "        if success:\n",
    "            results['completed_jobs'].append({\n",
    "                'job_id': job_id,\n",
    "                'time': job_time,\n",
    "                'images': job_queue.iloc[job_id]['num_images']\n",
    "            })\n",
    "            results['total_features'] += job_queue.iloc[job_id]['num_images']\n",
    "        else:\n",
    "            results['failed_jobs'].append(job_id)\n",
    "        \n",
    "        # Clear GPU memory periodically\n",
    "        if job_id % 10 == 0 and torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    results['total_time'] = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nüèÅ BATCH EXECUTION COMPLETE\")\n",
    "    print(f\"   ‚úÖ Completed: {len(results['completed_jobs'])}/{total_jobs} jobs\")\n",
    "    print(f\"   ‚ùå Failed: {len(results['failed_jobs'])} jobs\")\n",
    "    print(f\"   ‚è±Ô∏è Total time: {results['total_time']/60:.1f} minutes\")\n",
    "    print(f\"   üñºÔ∏è Total features: {results['total_features']:,}\")\n",
    "    \n",
    "    if results['completed_jobs']:\n",
    "        avg_time = np.mean([j['time'] for j in results['completed_jobs']])\n",
    "        print(f\"   üìä Average job time: {avg_time:.1f}s\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# COMMENTED OUT - UNCOMMENT TO RUN FULL EXTRACTION\n",
    "# This will process all jobs and may take hours!\n",
    "\n",
    "# results = run_all_jobs(job_queue, max_jobs=5)  # Test with 5 jobs first\n",
    "\n",
    "print(\"‚ö†Ô∏è Batch execution commented out for safety\")\n",
    "print(\"Uncomment and modify max_jobs parameter to run full extraction\")\n",
    "print(f\"Total jobs available: {len(job_queue)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3e0864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Feature Manifest Generation\n",
    "\n",
    "def create_feature_manifest(features_dir: str) -> pd.DataFrame:\n",
    "    \"\"\"Create comprehensive manifest of extracted features\"\"\"\n",
    "    \n",
    "    print(f\"üìä Creating feature manifest from {features_dir}\")\n",
    "    \n",
    "    features_path = Path(features_dir)\n",
    "    encoder_dir = features_path / f\"encoder_{CONFIG['encoder_name']}\"\n",
    "    \n",
    "    if not encoder_dir.exists():\n",
    "        print(f\"‚ö†Ô∏è Encoder directory not found: {encoder_dir}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Collect all feature files\n",
    "    feature_files = list(encoder_dir.glob('*.npz'))\n",
    "    print(f\"   üìÅ Found {len(feature_files)} feature files\")\n",
    "    \n",
    "    if not feature_files:\n",
    "        print(\"   ‚ö†Ô∏è No feature files found\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    manifest_data = []\n",
    "    \n",
    "    for feature_file in tqdm(feature_files, desc=\"Building manifest\"):\n",
    "        try:\n",
    "            # Load metadata without loading full features\n",
    "            with np.load(feature_file) as data:\n",
    "                manifest_data.append({\n",
    "                    'image_id': str(data['image_id']),\n",
    "                    'image_path': str(data['image_path']),\n",
    "                    'feature_file': str(feature_file),\n",
    "                    'encoder_name': str(data['encoder_name']),\n",
    "                    'feature_shape': data['features'].shape,\n",
    "                    'feature_dtype': str(data['features'].dtype),\n",
    "                    'file_size': feature_file.stat().st_size,\n",
    "                    'extraction_time': str(data['extraction_time']) if 'extraction_time' in data else None,\n",
    "                    'class_name': Path(data['image_path']).parent.name\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Error reading {feature_file}: {e}\")\n",
    "    \n",
    "    if not manifest_data:\n",
    "        print(\"   ‚ùå No valid feature files found\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    manifest_df = pd.DataFrame(manifest_data)\n",
    "    \n",
    "    # Add summary statistics\n",
    "    print(f\"\\n‚úÖ Feature manifest created:\")\n",
    "    print(f\"   üìä Total features: {len(manifest_df):,}\")\n",
    "    print(f\"   üè∑Ô∏è Classes: {manifest_df['class_name'].nunique()}\")\n",
    "    print(f\"   üóúÔ∏è Feature dtype: {manifest_df['feature_dtype'].iloc[0]}\")\n",
    "    print(f\"   üìê Feature shape: {manifest_df['feature_shape'].iloc[0]}\")\n",
    "    print(f\"   üíæ Total size: {manifest_df['file_size'].sum() / 1e6:.1f}MB\")\n",
    "    \n",
    "    # Class distribution\n",
    "    class_counts = manifest_df['class_name'].value_counts()\n",
    "    print(f\"\\nüìã Class distribution (top 10):\")\n",
    "    for class_name, count in class_counts.head(10).items():\n",
    "        print(f\"   {class_name}: {count} features\")\n",
    "    \n",
    "    return manifest_df\n",
    "\n",
    "def save_manifest(manifest_df: pd.DataFrame, features_dir: str) -> str:\n",
    "    \"\"\"Save feature manifest to CSV\"\"\"\n",
    "    manifest_file = Path(features_dir) / 'manifest_features.v001.csv'\n",
    "    manifest_df.to_csv(manifest_file, index=False)\n",
    "    \n",
    "    print(f\"üíæ Manifest saved: {manifest_file}\")\n",
    "    return str(manifest_file)\n",
    "\n",
    "# Generate manifest if features exist\n",
    "encoder_dir = Path(CONFIG['features_dir']) / f\"encoder_{CONFIG['encoder_name']}\"\n",
    "if encoder_dir.exists():\n",
    "    manifest = create_feature_manifest(CONFIG['features_dir'])\n",
    "    if not manifest.empty:\n",
    "        manifest_file = save_manifest(manifest, CONFIG['features_dir'])\n",
    "        print(f\"‚úÖ Feature pipeline ready for head-only training!\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No features found - run feature extraction jobs first\")\n",
    "else:\n",
    "    print(f\"üìã Manifest will be created after feature extraction\")\n",
    "    print(f\"Expected location: {CONFIG['features_dir']}/manifest_features.v001.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
