{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d11f8b45",
   "metadata": {},
   "source": [
    "# ðŸŒ¿ Plant Disease Detection â€” Immersive Modeling Notebook\n",
    "\n",
    "This notebook is your one-stop, end-to-end pipeline to build, evaluate, and export state-of-the-art plant disease classifiers. It includes robust data handling, model baselines, advanced transfer learning, ensembles, uncertainty, and explainability.\n",
    "\n",
    "What you'll get:\n",
    "- Clean data loading and splitting\n",
    "- Strong baselines (MobileNetV2)\n",
    "- Advanced models (EfficientNetB0, ResNet50V2, InceptionV3)\n",
    "- Optional lightweight ensemble\n",
    "- Mixed precision for speed\n",
    "- Class imbalance handling\n",
    "- Checkpoints + Early stopping\n",
    "- Grad-CAM explainability\n",
    "- Export to SavedModel and Keras 3 formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2767e895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import os, sys, math, json, random, pathlib, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "# Model families\n",
    "from tensorflow.keras.applications import (\n",
    "    MobileNetV2,\n",
    "    EfficientNetB0,\n",
    "    ResNet50V2,\n",
    "    InceptionV3,\n",
    ")\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"Keras:\", keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70474dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration â€” adjust as needed\n",
    "DATA_PATH = \"data\"  # root folder with class subfolders\n",
    "IMG_SIZE = 256\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 25\n",
    "LEARNING_RATE = 3e-4\n",
    "MODEL_OUT_DIR = \"models_out\"\n",
    "EXPORT_TAG = \"v1\"\n",
    "\n",
    "# Mixed precision for speed on modern GPUs/CPUs\n",
    "try:\n",
    "    mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "    print(\"Mixed precision enabled.\")\n",
    "except Exception as e:\n",
    "    print(\"Mixed precision not enabled:\", e)\n",
    "\n",
    "os.makedirs(MODEL_OUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2762b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "train_ds = image_dataset_from_directory(\n",
    "    DATA_PATH,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=SEED,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode=\"categorical\",\n",
    ")\n",
    "val_ds = image_dataset_from_directory(\n",
    "    DATA_PATH,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=SEED,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode=\"categorical\",\n",
    ")\n",
    "\n",
    "CLASS_NAMES = train_ds.class_names\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "CLASS_TO_IDX = {c:i for i,c in enumerate(CLASS_NAMES)}\n",
    "print(\"Classes (\", NUM_CLASSES, \"):\", CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce42addc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance pipeline and caching\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def norm(x):\n",
    "    x = tf.cast(x, tf.float32) / 255.0\n",
    "    return x\n",
    "\n",
    "aug = keras.Sequential([\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    layers.RandomRotation(0.15),\n",
    "    layers.RandomZoom(0.15),\n",
    "    layers.RandomContrast(0.1),\n",
    "    layers.GaussianNoise(0.05),\n",
    "], name=\"augmentation\")\n",
    "\n",
    "train_ds = train_ds.map(lambda x,y: (aug(norm(x), training=True), y), num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.map(lambda x,y: (norm(x), y), num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56297d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights to mitigate imbalance\n",
    "from collections import Counter\n",
    "\n",
    "# Re-scan directory to compute class distribution\n",
    "counts = Counter()\n",
    "root = pathlib.Path(DATA_PATH)\n",
    "for cls in CLASS_NAMES:\n",
    "    counts[CLASS_TO_IDX[cls]] += len(list((root/cls).glob(\"*.jpg\"))) + len(list((root/cls).glob(\"*.jpeg\"))) + len(list((root/cls).glob(\"*.png\")))\n",
    "\n",
    "total = sum(counts.values())\n",
    "class_weights = {i: total/(NUM_CLASSES*counts[i]) for i in range(NUM_CLASSES)}\n",
    "print(\"Class weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e630189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility: compile and callbacks\n",
    "\n",
    "def build_head(x, num_classes):\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    out = layers.Dense(num_classes, activation=\"softmax\", dtype=\"float32\")(x)\n",
    "    return out\n",
    "\n",
    "\n",
    "def compile_model(model: keras.Model, lr=LEARNING_RATE):\n",
    "    opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\", keras.metrics.TopKCategoricalAccuracy(k=3, name=\"top3\")],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_callbacks(name_prefix: str):\n",
    "    ckpt = keras.callbacks.ModelCheckpoint(\n",
    "        os.path.join(MODEL_OUT_DIR, f\"{name_prefix}_best.keras\"),\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        mode=\"max\",\n",
    "        verbose=1,\n",
    "    )\n",
    "    early = keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=5, restore_best_weights=True)\n",
    "    reduce = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, verbose=1)\n",
    "    tensorboard = keras.callbacks.TensorBoard(log_dir=os.path.join(MODEL_OUT_DIR, f\"logs_{name_prefix}\"))\n",
    "    return [ckpt, early, reduce, tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab417936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model â€” MobileNetV2\n",
    "base = MobileNetV2(include_top=False, weights=\"imagenet\", input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "base.trainable = False\n",
    "inp = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = base(inp, training=False)\n",
    "out = build_head(x, NUM_CLASSES)\n",
    "model_mobilenet = keras.Model(inp, out, name=\"MobileNetV2_Base\")\n",
    "compile_model(model_mobilenet)\n",
    "model_mobilenet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f146d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline\n",
    "hist_mobilenet = model_mobilenet.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=get_callbacks(\"mobilenet\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a4da70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune baseline\n",
    "base.trainable = True\n",
    "for layer in base.layers[:-30]:\n",
    "    layer.trainable = False\n",
    "compile_model(model_mobilenet, lr=1e-4)\n",
    "\n",
    "hist_mobilenet_ft = model_mobilenet.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=get_callbacks(\"mobilenet_ft\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f6733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced models â€” EfficientNetB0, ResNet50V2, InceptionV3\n",
    "\n",
    "def build_transfer_model(backbone, preprocess_fn, name_prefix):\n",
    "    backbone.trainable = False\n",
    "    inp = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    x = preprocess_fn(inp)\n",
    "    x = backbone(x, training=False)\n",
    "    out = build_head(x, NUM_CLASSES)\n",
    "    m = keras.Model(inp, out, name=name_prefix)\n",
    "    return compile_model(m)\n",
    "\n",
    "m_eff = build_transfer_model(EfficientNetB0(include_top=False, weights=\"imagenet\", input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "                             tf.keras.applications.efficientnet.preprocess_input,\n",
    "                             \"EfficientNetB0\")\n",
    "\n",
    "m_res = build_transfer_model(ResNet50V2(include_top=False, weights=\"imagenet\", input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "                             tf.keras.applications.resnet_v2.preprocess_input,\n",
    "                             \"ResNet50V2\")\n",
    "\n",
    "m_inc = build_transfer_model(InceptionV3(include_top=False, weights=\"imagenet\", input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "                             tf.keras.applications.inception_v3.preprocess_input,\n",
    "                             \"InceptionV3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0940532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train advanced models briefly (you can increase epochs later)\n",
    "HISTS = {}\n",
    "for name, m in [(\"EfficientNetB0\", m_eff), (\"ResNet50V2\", m_res), (\"InceptionV3\", m_inc)]:\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    hist = m.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=EPOCHS,\n",
    "        class_weight=class_weights,\n",
    "        callbacks=get_callbacks(name),\n",
    "    )\n",
    "    HISTS[name] = hist.history\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bb86e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional lightweight ensemble â€” average logits\n",
    "class SimpleEnsemble(keras.Model):\n",
    "    def __init__(self, models):\n",
    "        super().__init__()\n",
    "        self.models = models\n",
    "    def call(self, x, training=False):\n",
    "        preds = [m(x, training=training) for m in self.models]\n",
    "        return tf.reduce_mean(tf.stack(preds, axis=0), axis=0)\n",
    "\n",
    "ensemble = SimpleEnsemble([m_eff, m_res, m_inc])\n",
    "ensemble.compile(optimizer=keras.optimizers.Adam(LEARNING_RATE),\n",
    "                 loss=\"categorical_crossentropy\",\n",
    "                 metrics=[\"accuracy\", keras.metrics.TopKCategoricalAccuracy(k=3, name=\"top3\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7fa1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate and choose best model by val accuracy\n",
    "VAL_SCORES = {}\n",
    "for name, m in [(\"MobileNetV2\", model_mobilenet), (\"EfficientNetB0\", m_eff), (\"ResNet50V2\", m_res), (\"InceptionV3\", m_inc)]:\n",
    "    loss, acc, top3 = m.evaluate(val_ds, verbose=0)\n",
    "    VAL_SCORES[name] = {\"loss\": float(loss), \"acc\": float(acc), \"top3\": float(top3)}\n",
    "\n",
    "# Ensemble score\n",
    "loss, acc, top3 = ensemble.evaluate(val_ds, verbose=0)\n",
    "VAL_SCORES[\"Ensemble\"] = {\"loss\": float(loss), \"acc\": float(acc), \"top3\": float(top3)}\n",
    "\n",
    "print(json.dumps(VAL_SCORES, indent=2))\n",
    "\n",
    "BEST_NAME = max(VAL_SCORES, key=lambda k: VAL_SCORES[k][\"acc\"])\n",
    "print(\"Best model:\", BEST_NAME, VAL_SCORES[BEST_NAME])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a848c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export best model and ensemble\n",
    "BEST = {\n",
    "    \"MobileNetV2\": model_mobilenet,\n",
    "    \"EfficientNetB0\": m_eff,\n",
    "    \"ResNet50V2\": m_res,\n",
    "    \"InceptionV3\": m_inc,\n",
    "    \"Ensemble\": ensemble,\n",
    "}[BEST_NAME]\n",
    "\n",
    "save_dir = os.path.join(MODEL_OUT_DIR, BEST_NAME + \"_\" + EXPORT_TAG)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# SavedModel (for TF Serving and Keras 3 TFSMLayer)\n",
    "BEST.save(os.path.join(save_dir, \"savedmodel\"), save_format=\"tf\")\n",
    "print(\"Saved SavedModel at:\", os.path.join(save_dir, \"savedmodel\"))\n",
    "\n",
    "# Keras v3 .keras format\n",
    "BEST.save(os.path.join(save_dir, BEST_NAME + \".keras\"))\n",
    "print(\"Saved .keras at:\", os.path.join(save_dir, BEST_NAME + \".keras\"))\n",
    "\n",
    "# Write meta info\n",
    "with open(os.path.join(save_dir, \"meta.json\"), \"w\") as f:\n",
    "    json.dump({\n",
    "        \"best\": BEST_NAME,\n",
    "        \"val_scores\": VAL_SCORES,\n",
    "        \"classes\": CLASS_NAMES,\n",
    "        \"img_size\": IMG_SIZE,\n",
    "        \"export_tag\": EXPORT_TAG,\n",
    "    }, f, indent=2)\n",
    "print(\"Export complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef810ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grad-CAM explainability for a batch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def grad_cam(model, images, class_index=None, layer_name=None):\n",
    "    if layer_name is None:\n",
    "        # try last conv\n",
    "        for l in reversed(model.layers):\n",
    "            if isinstance(l, layers.Conv2D):\n",
    "                layer_name = l.name\n",
    "                break\n",
    "    grad_model = keras.Model([model.inputs], [model.get_layer(layer_name).output, model.output])\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_out, preds = grad_model(images)\n",
    "        if class_index is None:\n",
    "            class_index = tf.argmax(preds[0])\n",
    "        loss = preds[:, class_index]\n",
    "    grads = tape.gradient(loss, conv_out)\n",
    "    guided = tf.reduce_mean(grads, axis=(1,2))\n",
    "    cam = tf.reduce_sum(tf.multiply(guided[:, None, None, :], conv_out), axis=-1)\n",
    "    cam = tf.maximum(cam, 0)\n",
    "    cam = cam / (tf.reduce_max(cam) + 1e-8)\n",
    "    cam = tf.image.resize(cam[..., None], (IMG_SIZE, IMG_SIZE))\n",
    "    return cam\n",
    "\n",
    "# Show Grad-CAM for a small batch from val_ds\n",
    "for batch in val_ds.take(1):\n",
    "    imgs, labels = batch\n",
    "    cams = grad_cam(BEST, imgs)\n",
    "    plt.figure(figsize=(12,6))\n",
    "    for i in range(min(6, imgs.shape[0])):\n",
    "        plt.subplot(2,6,i+1)\n",
    "        plt.imshow(imgs[i].numpy())\n",
    "        plt.axis('off')\n",
    "        plt.subplot(2,6,6+i+1)\n",
    "        heat = tf.squeeze(cams[i]).numpy()\n",
    "        plt.imshow(imgs[i].numpy())\n",
    "        plt.imshow(heat, cmap='jet', alpha=0.35)\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(f\"Grad-CAM on {BEST_NAME}\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_engineer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
